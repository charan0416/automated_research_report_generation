{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5453311e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ok\n"
     ]
    }
   ],
   "source": [
    "print(\"all ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0818a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to path: d:\\ai_projects\\mlops_project_by_sunny\\automated-research-report-generation\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Get project root â€” one level up from 'research_and_analyst'\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Project root added to path:\", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efe453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_and_analyst.utils.model_loader import ModelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e55ff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-11-26T09:13:10.025819Z\", \"level\": \"warning\", \"event\": \"OPENAI_API_KEY is missing from environment\"}\n",
      "{\"timestamp\": \"2025-11-26T09:13:10.027819Z\", \"level\": \"info\", \"event\": \"GOOGLE_API_KEY loaded from environment\"}\n",
      "{\"timestamp\": \"2025-11-26T09:13:10.029822Z\", \"level\": \"warning\", \"event\": \"GROQ_API_KEY is missing from environment\"}\n",
      "{\"timestamp\": \"2025-11-26T09:13:10.031874Z\", \"level\": \"warning\", \"event\": \"ASTRA_DB_API_ENDPOINT is missing from environment\"}\n",
      "{\"timestamp\": \"2025-11-26T09:13:10.034826Z\", \"level\": \"warning\", \"event\": \"ASTRA_DB_APPLICATION_TOKEN is missing from environment\"}\n",
      "{\"timestamp\": \"2025-11-26T09:13:10.035819Z\", \"level\": \"warning\", \"event\": \"ASTRA_DB_KEYSPACE is missing from environment\"}\n",
      "{\"config_keys\": [\"astra_db\", \"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-26T09:13:10.041819Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n"
     ]
    }
   ],
   "source": [
    "model_loader = ModelLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b3e9305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-11-26T09:13:12.834873Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n"
     ]
    }
   ],
   "source": [
    "llm=model_loader.load_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d585280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I help you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91769b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a9b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import AIMessage,HumanMessage , SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cd30ec",
   "metadata": {},
   "source": [
    "#health\n",
    "\n",
    "Analyst(\n",
    "        name=\"Dr. Neha Patel\",\n",
    "        role=\"Medical Data Scientist\",\n",
    "        affiliation=\"Stanford Medicine\",\n",
    "        description=\"Focuses on predictive models for patient outcomes.\"\n",
    "        ),\n",
    "\n",
    "Analyst(\n",
    "    name=\"Dr. Arun Verma\",\n",
    "    role=\"Ethics Researcher\",\n",
    "    affiliation=\"WHO\",\n",
    "    description=\"Explores ethical implications of AI in diagnostics.\"\n",
    "),\n",
    "Analyst(\n",
    "    name=\"Ms. Priya Sharma\",\n",
    "    role=\"Policy Analyst\",\n",
    "    affiliation=\"Ministry of Health\",\n",
    "    description=\"Investigates AI policy and compliance frameworks.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b0d1dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyst(BaseModel):\n",
    "    name: str = Field(description=\"Name of the analyst.\")\n",
    "    role: str = Field(description=\"Role of the analyst in the context of the topic.\")\n",
    "    affiliation: str = Field(description=\"Primary affiliation of the analyst.\")\n",
    "    description: str = Field(description=\"Description of the analyst focus, concerns, and motives.\")\n",
    "    \n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "278c7ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analyst(name='sunny savita', role='genai eng', affiliation='AI Research LAB', description='I am genai developer as well as mentor')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Analyst(\n",
    "    name=\"sunny savita\",\n",
    "    role=\"genai eng\",\n",
    "    affiliation=\"AI Research LAB\",\n",
    "    description=\"I am genai developer as well as mentor\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36ad0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst = Analyst(\n",
    "    name=\"sunny savita\",\n",
    "    role=\"genai eng\",\n",
    "    affiliation=\"AI Research LAB\",\n",
    "    description=\"I am genai developer as well as mentor\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e9ba7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sunny savita'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a147e7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'genai eng'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst.role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "449cd50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI Research LAB'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst.affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05f5b7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sunny savita\n",
      "Role: genai eng\n",
      "Affiliation: AI Research LAB\n",
      "Description: I am genai developer as well as mentor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(analyst.persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ef022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "208c2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perspectives(BaseModel):\n",
    "       analysts: List[Analyst] = Field(description=\"Comprehensive list of analysts with their roles and affiliations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5dd3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnalystsState(TypedDict):\n",
    "    topic: str #research topic\n",
    "    max_analysts: int # number of analyst\n",
    "    human_analyst_feedback: str # Human feedback\n",
    "    analysts: List[Analyst] # Analyst asking questions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9ea018f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'finance',\n",
       " 'max_analysts': 5,\n",
       " 'human_analyst_feedback': 'give the real info'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GenerateAnalystsState(\n",
    "    topic = \"finance\",\n",
    "    max_analysts= 5,\n",
    "    human_analyst_feedback= \"give the real info\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52b4a3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Analyst(name='Dr. Neha Patel', role='Medical Data Scientist', affiliation='Stanford Medicine', description='Focuses on predictive models for patient outcomes.'),)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Analyst(\n",
    "        name=\"Dr. Neha Patel\",\n",
    "        role=\"Medical Data Scientist\",\n",
    "        affiliation=\"Stanford Medicine\",\n",
    "        description=\"Focuses on predictive models for patient outcomes.\"\n",
    "    ),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70ffa4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_instructions=\"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
    "\n",
    "1. First, review the research topic:\n",
    "{topic}\n",
    "        \n",
    "2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts: \n",
    "        \n",
    "{human_analyst_feedback}\n",
    "    \n",
    "3. Determine the most interesting themes based upon documents and / or feedback above.\n",
    "                    \n",
    "4. Pick the top {max_analysts} themes.\n",
    "\n",
    "5. Assign one analyst to each theme.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae9b3672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\\n\\n1. First, review the research topic:\\neducation\\n\\n2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts: \\n\\nplease exaplain only on AI\\n\\n3. Determine the most interesting themes based upon documents and / or feedback above.\\n\\n4. Pick the top 4 themes.\\n\\n5. Assign one analyst to each theme.', 'Generate the set of analysts.']\n"
     ]
    }
   ],
   "source": [
    "print([analyst_instructions.format(\n",
    "        topic=\"education\",\n",
    "        max_analysts=4,\n",
    "        human_analyst_feedback=\"please exaplain only on AI\"\n",
    "        \n",
    "        )] + [\"Generate the set of analysts.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a176d",
   "metadata": {},
   "source": [
    "['You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\\n\\n1. First, review the research topic:\\neducation\\n\\n2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts: \\n\\nplease exaplain only on AI\\n\\n3. Determine the most interesting themes based upon documents and / or feedback above.\\n\\n4. Pick the top 4 themes.\\n\\n5. Assign one analyst to each theme.', 'Generate the set of analysts.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39e7d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analyst(state:GenerateAnalystsState):\n",
    "    \"\"\"\n",
    "    it is creating my analyst\n",
    "    \n",
    "    \"\"\"\n",
    "    topic = state[\"topic\"]\n",
    "    max_analysts = state[\"max_analysts\"]\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\",\"\")\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(Perspectives)\n",
    "    \n",
    "    system_messages = analyst_instructions.format(\n",
    "        topic=topic,\n",
    "        max_analysts=max_analysts,\n",
    "        human_analyst_feedback=human_analyst_feedback\n",
    "        \n",
    "        )\n",
    "    analysts = structured_llm.invoke([SystemMessage(content=system_messages)]+ [HumanMessage(content=\"Generate the set of analysts.\")])\n",
    "    \n",
    "    # Write the list of analysis to state\n",
    "    return {\"analysts\": analysts.analysts}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44d0a2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysts': [Analyst(name='Dr. Emily Carter', role='Public Health Researcher', affiliation='National Institutes of Health', description='Focuses on preventative healthcare and the impact of public health policies on community well-being. Concerned with health equity and access to care for underserved populations.'),\n",
       "  Analyst(name='Dr. David Chen', role='Healthcare Economist', affiliation='Harvard Medical School', description='Analyzes healthcare costs, insurance models, and the economic impact of medical innovations. Motivated by finding sustainable and efficient solutions to healthcare financing challenges.')]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_analyst(\n",
    "    {'topic': 'health',\n",
    "    'max_analysts': 2,\n",
    "    'human_analyst_feedback': 'give the real info'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acbd701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback(state):\n",
    "    \"\"\" No-op node that should be interrupted on \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2abcfccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    feedback = (state.get(\"human_analyst_feedback\") or \"\").strip().lower()\n",
    "    if feedback and feedback not in [\"\", \"none\", \"skip\", \"done\", \"continue\"]:\n",
    "        return \"create_analyst\"\n",
    "    return END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aef85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def should_continue(state):\n",
    "#     \"\"\" Return the next node to execute \"\"\"\n",
    "#     human_analyst_feedback = state.get(\"human_analyst_feedback\",None)\n",
    "#     if human_analyst_feedback:\n",
    "#         return \"create_analyst\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a7596bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e942924",
   "metadata": {},
   "source": [
    "## First Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69a8b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(GenerateAnalystsState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "914c955f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x26395136610>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"create_analyst\",create_analyst)\n",
    "builder.add_node(\"human_feedback\", human_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd30a26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x26395136610>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_edge(START,\"create_analyst\")\n",
    "builder.add_edge(\"create_analyst\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\"human_feedback\",\n",
    "                        should_continue,\n",
    "                        [\"create_analyst\",\n",
    "                        END])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a60c6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73530c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(interrupt_before= [\"human_feedback\"],checkpointer= memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37a56840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKkAAAF3CAIAAABR9PyTAAAQAElEQVR4nOydB0AT1x/H3yUhIWwQ2Rtxorhnq38VtK66sFr3qlpnXWgd1WqdRWuV4h5Vq9Y6q61a66p14kDFhUxBpuwZklz+v+QwBkgiSQ0X793n75/evXs3ct/3fu/33r3Bk8lkiAVLeIgFV1jt8YXVHl9Y7fGF1R5fWO3xxai1f51S+uh6Xk56WWkhiWQysbjCUQ4HkaT6EC6PkEpkihCCJN9WYglEyFDlOq0ysio8HkciISudziE4pIxUvSzXhJCKK5zLF0AsZGrGcfTkt+hiwxfykbFCGGH9PjWx6MKB9NwM+VvmcpHQksPlcQgeIkVEhXgchCpqrwzh8pBUIt8AGWRkhQiwS1Q6Ca4s156oGEhAIMEhZKpJ583VlBtcEyStmCJ5AoKUkuIymahYKhEjvhDVdjft/6UbMj6MS/uSQukvqxNKi2TmNoR/e5tWQbXQB86l39LjogpL8mW1XE0+n+OJjAkj0v74T8mvYkqdffgDp3kgZlGYW3b8p1cF2dKW3Wxad7dHxoGxaL/rmziw0l+s9EHMJS6q4K996bVc+INmGEXiNgrt9yxLsLHn9pvsjjBg5+JYv2aWHQc4ILqhX/vtC2PtXEwGTmGandfCzm/izK14Q+bQ/JM5iFb2fBtn54yX8MC4ZT5F+ZI/dqcgWqFT+3N7U6EuNHAqXsJTgPyJUcWvU0sQfdCp/Yv7RQNnuCBcqdPM/NgmOrM+bdofXJNoVYtr5yBEuNJtuLOkTHb9j0xEE7Rpn5Um7jGGfl+XXnyamD/6Nw/RBD3an9ubIm/sdDVHePPJSGeJCKXTVOrToz203zl4mKKaZf78+SdPnkS6ExQU9OrVK2QYTC24N09mIzqgR/vSYtK/vRWqWZ48eYJ0JzU1NScnBxkMe1eT16kiRAc0tO3kZoj2r06aur4OMgzXrl3bu3fv48eP7e3tAwICpk2bBhstW7akjlpYWFy+fLmwsHD//v03btyIjY2Fo506dfryyy9NTeWmKCQkhMvlOjs7w0UmTpy4detW6kSIs27dOvS+uXMh+8657ElrDfU2tEBDvk94Vsw1WLeBZ8+ezZgxo1WrVkeOHAEVo6Ojly5dihQJAv4uXrwYhIeNQ4cO7dmzZ8SIERs2bID458+f37ZtG3UFExOTGAXr168PDg6GCBAIhYUhhAc86pmSUkQLNPTdKMwRczkEMgyRkZGQfceOHcvhcJycnBo2bAgqVo02fPjwrl27ent7U7sPHjy4fv369OnTYZsgiJSUlH379lFmwNA4uJmRNLWq06C9jCQQMpT2TZs2LS0t/eqrr9q0adOxY0d3d3eltVcFMjcY/CVLloBhkEjk3Tzs7OyURyFN1Izw9EKDzRdacaWVOlu9P+rXr79x48batWtv2rSpf//+kydPhjxdNRocBSMPEU6cOHHnzp0xY8aoHhUIBKimyKSvWZcG7V19BAb1L9u3bw/l+qlTp6Ckz8vLAxtA5Wwl4N4ePXp08ODBoD2UCxBSUFCAaCIlpoTDRbRAg/bO3uakBL18YZDXfffuXSi5YQOyfu/evWfPng26Qj1NNY5YLC4pKXFwKG9VLCsr++effxBNvHxebEJTd0566vdcE+Lh5XxkAMDCg3t/7NgxqJRHRUWBPw+JACpsYMZB7Js3b4KFBzfQy8vr999/T05Ozs3NXbZsGXgJ+fn5RUVFVS8IMeEvVATgasgApCeIrOxNEB3Qo72LryAjySANGuDAgyUPDQ2FxrgJEyaYm5tDuc7jyV1acP4jIiLAEkCmX7lyJXhzUIXr169f69atp06dCruBgYHg4Ve6oJubW58+fbZs2QIuAjIApUWy1t3o6ZJKW7+dsJkxU3+goUHDqLhyNPPxjbzJofS8B9q+4wktuL+sTkR48ywiv06ABaIJ2sblDJ3nsXNxvJYIYLTFlUbiKJBKpVBgQwuM2rOgzmZjY4MMALQaQZVB7SHwFqHBQO0j+fj47Nq1S+1ZN/7IEItk3UY4IZqgs6/m4R9eFuZKx37rrfaofvUuS0tLZDA0PZJIJNLUJAAJAr4gqD0UPiemw6e2AR1pG39Ccz/drfNj/ZpZdBnsiDBj/8oEnoAzZDadfRVp7qc7cbXvs4iCxzfo+YBNF7+uTxCVkvQKj4xkbMbmuTHNAq3bdq+NMODg2gQOjzN4Fv29k41lTBYUfrYOJp+HGNdoxffOriXxBCEbs9Qohp4Z0VjM3UvjivLJZl2sOvRmYB/O09tfJTwtcasr7DfJFRkHxjUGO+KvrLt/55KkzL2uaeAwJ6H5Bz8tSNLzwut/ZOekiXl8YsBUZzsnI+qTboxzL1w5mhF9r0BULIMKs9CSsLIzMbXg8QVcScXZMeAoPDuhmExDvqHYVT2K0NuQ8qMQKEMcApGVwituUxEIjjwyFUJdDf6QMpVbq7sFl0OIxZKSAmlhjqSkmJRJkbkNt21vu/rNrZGRYYzaK7l6IjM1vri4QCoRyUhZ5dlNKglQSfu3iaI8sup2eUwwMBzVHkSKlCH/r2K6DcWVy88i3txMuStTTXcqlzUx4XB4Mqi/WdrwvBoKm3U23ukjjFp7Q7No0aIOHTr06NEDYQnW82xJJBLqEx+esNqz2mMJqz2+wHdC+P6GcIXN92y+xxJWe3xhtccXVnt8YbXHF1Z7fGG1xxdWe3xh23bwhc33+MJqjy+s9vjClveYQpLUilc0j06hEXy1x9zgI1Z7hDGs9viC74/H3NFDbL5HGIPvj5fJZC4u+K7YgnDWHjJ9UlISwhista803yZusNrjC6s9vrDa4wvW2kulNK1YYRzg+yUD4HK5OGd9rLXH3Ozj3bDFao8trPb4wmqPL6z2+MJqjy+s9vjCao8vrPb4grn2OM6r2bRpU0KBMgRewkcffWSgVdCMFhzbdNu1a8epiKOj4+jRoxFm4Kj9qFGjVFe9Bvz8/Fq0aIEwA0ft27Zt26RJE+WutbX1kCFDEH5g+h1v5MiRyqzv7e3doUMHhB+Yah8QENCsWTPYMDc3Hzx4MMKS/+rnXzmeVlqIVPu/cDhIMcJVuUuQ5NtbgHPNIZCUfLtb6f5y75tal+ANXC6q1L/mzYoZSKYmkFrhoGKgurvkFxRE3r/HF5i2a9OGrLTgBimTqVvksvw61Pob6o9WPlZpXQ7lyhuakMcn36wIoRl4J7aOvNbd7NF/QH/tD29IeJ0s4fBAS45EZUULDpcgpaq7iKyQMuQvQBlBjSoceCQSyVS1J0h4HyRRIQ4pIzjwmlDlQJXFLpTXV10kpeJ95VJRJ1a6DlJH+S0qprkq19QYSCiMrOozV40s/z/5bklMBPK3Cq+xZZBtK32X0dazbefc/pTsNEnwHA+hkI9YaCLhcd7VE5lmVtxGbfVZAliffH9yc1Jmqmjw7DqIxQjY/11M589q1W9li3REH18vJU7UursdYjEOHL341//QZ1FZnbWPfZQPf739We2NBd8Aa1GxPk6bzuV9WXEF342FdoRWfKkY6YHO2kP1TIunykIDJKFfXQ3rb7hMQc9aOqv9B4+MeFdLkAZY7T98ZHpmfL201y+ZsRgIfeVg8/0HDyGryfIe39WTGQWb7xkA6+vhi6wGfT0WRqC79gTr5zME3bVnHT1jQ6ZnXtSrvx4rv1aOHjsU2K0NqjE4eurBhL6a/QcGpaS+Qozg+InDq9Ys0ekUvbPiB+/rpaWl5ubmIKbw/PkTVFPUkK9348bVHzetyczMqONbt1+/z3p88ikELlkawuVyHR2dD/2699ulazt+3CU7Oyt88/qoxw9KS0tbtWo3cvh4d3dP6grHjv968+bVp0+j+AJBQJPm48ZNcXVxux95Z9bsSXB02PC+HTp0+m7ZOolEsnNX+M1b/2ZkpPn7N+3f97O2bT+qzuNdvHTu4aP7+fl5Der7jxgxvlnTlkiRC/ft37Fh/bYl34YkJMT5+NQZFDzsk+59tDyS6mVnzPxCwBesXROmDFn8zZys7NfhYXtevkzYvWdL5IO7MpmsUaMmQz4b2bhx069mTXjw4B5E++uvP06euGhlaYUMie42X3cLA2928ZI548ZOWb1q40cfdV77/bK/L5yFcBMTk7j4GPi3Yvn6Jo2bSaXSmbMnwuuY+dWCXTt+tbWxmzxl1KuUZIj56FHkprDvGzUKWLYsdP68b3NyslesXAThoNCqFRtg45f9J0F42Ni4ae2Rowf69xt84JdTnTp2Bc2u/HNB++NBOluxapFIJIIrr1yxwcPDa+GimZAKqScsLCyAa86dvfji3xGdOgbCw6enp2l5JFV6ftL37r3b1KWoG0Gi7BbUq6ysDGSGdL9m9aZ132/mcXlwRzgKiaxBA/9u3XpdunDH0MKjmmnThQQOeToosAdst2rZtqiosLi4CMmbo4i0tJQt4ftMTU1hNzLyLuSGdaGbmzdrBbtfTvrq2vUrR48emD4tpGHDxrt3HnZz86BWO5CIxQsWzczLz7O2sla9Eeh37q/TQz8f/WmfgbDbs0ffqKgHe/dth0Sg5fHg7ju2HRIKhdbW8t6ukO9P/n7kUVQkdZZYLB41cgI8AGx379YbfktMzHNHR6fqPFLnzt3CwkPBogQPHAq7/167DH+7dOmelJQIaWXggM/r+tWHkCXfrH7w8F7NjwbXWXtFF3IdjD7YtNi4F4EK4SkmTZyh3Pb08KaEB+B1Qz6jhEeKuzQNaAEvBSkmwExJSf4pfN3TZ1FFRUVUhNyc7EraR0c/hSzVqmU7ZQhc4czZ36umkkpAWtyxMwxMTlbW6/KLq/gQ9es3ojYsFXkRLEE1H4nP5wd27fH332co7a9evdihfSfI0FAQ2NjYrl67NCiwJzyhv38AVcToib51PJ21l1HDZqoNiEGSpEBgqvYolJTKbXinkMk6d63wFuAdwd9r164s+mb2sKFjJk6Y4evrd+furZB5U6tejVJl2oxxlcJzsrO0aA82fMbM8c2btV68cCXkZkhzQd3bqkZQm9ar+Ui9ew04cfI3KLlq2dnfun0NbgGBAoHgxx+2//HnCSiewDtxcXEbPXJCUFBPpB9EjX3H0zGRQVbmcDhg598Zs1YtezC8K777QTWQy+HC39N/HgdXaPy4KVQgpbGaK9jXhr+zZy10dXVXDXdwcEKauXzlPCRQKLPh7qhijtdCNR8JkgUU4WfOnPTzqy8UmrVpUz7oE7wKKNTGjJ50795tsEwrV3/j6eVDFQE1hsH7boDw9eo1BHuuDNm+Iwze9ZTJsyrF9PWtW1JSAjopvWWotdtYy/M9uN9Ojs7KmGA81d7LzdVDoDAkShMKxSpYKTMzM6QZuDgYc0p44J2+ofKs6jwSUrgdUJFJTn4J9p9yDsCtefzkIVR2oLxr374jJIhPenaAAks/7Ql9v+Pp5efraGP69gmOiLjx6+F9UCUDN+rgoZ+9vX2rRmvRvHXr1u1DQ5eDEc7LywVTOenLEWfP/g6HoGYYcecmnA4O0W9HtZdNzAAAEABJREFUfqHip6Wnwl93Dy/4e/ny+SdPo0Dj0aMmgnMHTjgkL1BxTsjkDT+u1v54Pj5+UMz/fuooXPzW7euQEcHpgyqi9rO0PFIlunTunpWVCQYfEgEVAukG6gubt2xIfpUEft8vB3bDRfwbBcAhsFhQabx3PwL8VlQ9ZMb8Ha979975BXk/790GPhEY9glfTFO+hUpAhQ00WPbd10+ePIKaPXiIAwbIZ0UYO3YyuGOLFs8CwzCg/xCwz6mpr+Z/PX3hgu8Cu34CFW5wv+Hd/bB+65DBI8F+HDi0ByQ0N7do1LDJ7NmLtD9e1y7dExPjIMX8sGEVVEPmhSyFbHrg4J6Cgvy6dRtoOkvLI1WKCSmyRYs2mRnpyhQPzt2smQv2/Lz18G/7Ybdlizbr123x8vKB7T69BoABmBsy5fChPwUqzpAh0Hk8XtSN/MuHM0YtZQfjVRewQIMG94AU36tnP2QAUuNLzu15NW2DzoqwfbYMCLQ3v0pJOnb8kKentyZTRyNY9N0AA37w4B61h8C7Dtu4CxmGCxfP7tj5EzQPLP1mjb6d6A0IFtr36TMQmtjUHoL2VGQwoPYP/5CBIdj+elqwtLCEf4ih1Kyfz/bZYgR6aM8qb2zUVHu+/sO/WAwFOw4XW2rsOx7bR9voINh8jy81lu9lbLuescHmexYdYbXHF921J6U8PtYrKBsbMpmUZ4L0QGcVfRuaSqXsJGtGRFpiqX4N+jprL7QVmpoRV46mIhbjIP5Rob2bPr089LHevcY7Jj4uKisrQyx0c/FQkqhIEjzdXY9z9Zw/H4TfNv+lnYuJh5+ZrZOpjFRJQ+rml68UVnX1AYJqnqpyoiJARvy35iT1t1P8p8IqDRpOqfBcb3bUPGzloLfX0Hg19W+rPJTQXHuTkbLMVyWJT/NIKTFumS/Si/+0bsaB1Qn5ORJSUmGhjPePzJAtiQa9uMHg8AgTE5mtk0nwdE+kL3itjTh16tRhw4a1a9dO7dGhQ4cKBILdu3cjPMCrtvbw4UPV1dFUSUlJKSoqevr0aVhYGMIDjLSPiYlxdnY2NzdXe/Tx48eZmZkSieT48ePXrl1DGICR9loyPXDlyhVqOEReXt7atWvz8/MR08FI+wcPHgQEBGg6CtZe2ZU2OTk5JCQEMR0238uBZKEcR40UA28hcnh4OGI0uGifm5sLZtzDw0Pt0Zs3b2ZkZKiGlJaWHj58GDEaXL7jaS/sb9y4QZIkZHcLCwsbGxsTE5MjR44gpoOL9toL+z179lAbkN1Xrly5bNkyhAG42Hzt+V6JqanpvXv3UlOx+FKFS7temzZtoNZOTX2gnWfPnjk6Otra6rzM5AcHFjYf2m3q1atXHeGRfGalGp34hEawsPnVNPgUYPO3bNmCMAAL7bU7epVwcHA4c+YMwgA231fGzc1t1apVJMn8fmnML+/T0tKg4g7uW/VPadiwIcIA5ud7nTI9BXzCP3/+PGI6zNdep8Kewtra+vbt24jpMN/mQ77v1auXTqdAfE19e5gEw7WXSCTR0dG6lt8CgcDZ2RkxHYbbfD0MPsXkyZPhKz5iNAzXXg9HjwK+5kFrIGI0DLf5kO8HDhyIdGfx4sWM/9LB5nv1CIVC7bNvMwAmaw+tOiA8VNiQ7qSnpzO+yx6TtXdycoIPM6od8apPYmJiQUEBYjQML++9vb3j4+P9/f2RjrRo0aJ58+aI0TC8vPfy8kpISEC6w+Vyq/m9/8OF4dpT+R7pzvLly0+fPo0YDau9elJSUuBDPmI0DDdrnp6e4LUh3QkLCwOzjxgN88t70F6PVhrGC49w+Iarh9nPysrq1q0bYjrM114PVx8adlxdXRHTYf73ez3yPXzzxWH2Ddbmq0Eqldb8qtQ1D2vz1RAaGnrs2DHEdNh8r4acnBy2vGcCpqamNjY28E0PPu1U85TVq1cjDMBibIauZr+wsBCHIapYaK+T2Ydvvj179jTCZSzfO9hpHxgYqD1yZmamn58fwgCGj7/v0aNHcXFxQUGBMh/jM9TynTDZ14OqGqheWlrK4bw1b/b29trPgvhQubewsEBMh8k2f86cOfXq1YOGGmUIGLl3DrjZuXMn42fYomB4eb9o0SIfHx/lLmT61q1baz8FfD3wDxAGMH++nd9++y08PByMP0mSvr6+sItYFDDfzx80aBDYeUJBmzZt3hkfPuKpFhMMplq+XvzTfFKsa18G+WIX7zQpxH9YaFGGwHdXu9hG5csO6zcrL0WYm5fbwLNz7MMibetRyMh585atXbu24o3KF4LV+VEJmfx/Op1BLT5JyDgVT6zOz0TlTyuzsOQ6eQvRu59Oq80/9H18droU3rHUwJ+1ZAolawJ9F8ogFAus1My9/tNqHhx5nuOaIK9GZp+MdNESUZv2+9fGlRXJPu7v4ORtiVg+KJ7czLn7d1bzLlZte2jscapR+z3fxnH5qN9kH8TywXJgTYyLl6DPBPWraKn39R7fyCktIlnhP3Q6DXRKeiHSdFS99k9v55tasAuffvC41rEAN+XepUy1R9X7+aJSgsv0EUmYwOVy8l6rnytQvcCSMlJGMv8jJg6Iy6BNS70JZzM3vrDa44sm7f9LgxuLEQG+HkdD6a1J+w9zmViWKkDzDakhF7M2H19Y7fGF1Z7h6FHes64eQyAIjR+RNWvPunqMgCQ1fqllbT6+qNeeIDisyWcGWsp79S29Mhmpa4E/aHCPHTt/Qh8I/167/MWEoZ27tnz8+CF6H2z4cfWYcZ9R2337d927bwd6H8TFxcBDPnx4H+kLW7+vzMFDP8uQbP26LZ6e+PZRwFT74uKigCbNmzVtiTBGvfYcgpDq3nWSxzM5dvzXLVs38Pl8f/+mX89fZm0ln8O6R6+PRo2cMGTwSCra2u+XxcZGb92yPz4+duz4wWEbd23bsQnMmpOj85Aho0CPxUvmJCe/rF+/0bSpc+vXky93UlhY+NuR/bcjbiQkxNays2/fvtPYMV+amprCoX4DAseMnpSXl/vz3m1CobBVy3ZTp8ypVUvjwCuJRBLUvS1sJCTEnfz9CNy9UaMmZ8+d+v3U0fj4GG/vOl06dxs44HPl+D1Nh4qLi1esWnT/fgSE9+0TXPVGx08cPnv291cpSc2btZ41c4GNjXyB3Rs3rl68dO7ho/v5+XkN6vuPGDFemf7yC/K3bv3xzzMnra1tWrZo88X4aY6OlScMgKLkwMHdP6zf1qB+I1RNdC3voV6ge6dUdOWfv4uKCtes3jR3zjdRUZG7d2/WHt/ExAT+hv0UCinj4t8RjfwDtu/YBAXnvJCl585cF/AFGzeV95U+dvzQgYN7Bn82YuWKDRMnzrh85TworbzIr7/u5XA4J45f+Hn30UdRkXt+3qrlpjwe79KFO15ePn0/DYYNEP7vC2fXrP22rl/9A/t/Hz9uypGjB8LC11GRtRwKXbccEmjo95uXfxsanxB789a/qnc5c+ZkTk7WpElfLfz6u8jIO/AbkWKkHyQXkUg0f9638EM8PLwWLpqZnZ2FFCly/tfTX2dlQjEEKT4jM33+gumV5vyBh9m9Z8vihSt1EB7J3baaKO/NzMxHDB9HbV+7fgVSd3XO6tr1k+bNWsHG/zoGXrhw9tNPgxs2kE973bFj1/DN66FyCvnss0HDO3Xs6ulZPlQqKurB7YjrEydMp3ZdXd2HDxsr37KwhHwfHf0U6cKff55o0qTZVzPmw7atrd2YUZPWhi4bPnQsbGs6JJVKL10+Py9kCfWo8CTXb/yjek2hmRlYI8pC9O49ABJNWVkZGKod2w6BcYKcDeGQ78HwQGKFnwZJ5+nTqJ93H4EEAYfc3T0P/7afShYUkZF316xdCjfq0KET0gUOB3E1iPw+tW/s31S5bW1lUyYSVecsd3cvasNcMfTVx7sOtSs0FYrFYnhlAoEAMnfEnRur1yyJiY2mcgMoobxC3boNlNuWllZge1C1IUky6vGDkSO+UIY0a9YKAiHhfvxRZ02H7GxrIfmErW/9xHr1Gr548Uy527JFW2Wp0bBhY/EhMeRpF2dX8DN27AyLfHA3K+s1dTQ3Nwf+xsa+MDMzo4SX/yK/+osWfIfkhZ18Dv+XSQlQknbt8omy3NTlB2ocW/E+tVeddLz681aoDpCuukuxbfsmyIJg7SFbQykIlUkoF/W4V1UgbUEK27krHP6phufkZGs5RM24aiZ8u6gKpFTVOGAC3x5SRAOPhMvhzpg5Hop/sNuQIOCxKc8DyQeAFgoEppoe8seNayDF29nVQu8VDb4elzBc246U1G20G5j9U6ePBg8c2rtXfyqEyg3vBbDDkOG6BfWCIkY13MXZTcuhjIw02CgVlSoDIUOrxiktLVFuU3YI7Dy4KZCeoLAHs4/e5HgKSCslJcXynnXqkn73br3B8123fkXLlm2p8lEnNOUM9dqTUtl77KvJ5wvghyl3k5J0m9gaMl9JSYm9ffn4Enh9lQrX/4ivb92CwgKlvw23S0195eDgqOUQpRC4HfUUxQ2E37l7i/LkKWJiniu3nz9/AhWf2vYO4NtDkUQJj+Su8QVlHKjOgCf4PPop5ce9fJmwfsPKaVPmUiYN0h+4HRERN1asXLRr52Gq9lR9NGXjmuiED/YNfifU02B73/6dr19n6HQ6vDgoCM/I60vJYDnB2wLHoqAgX7+FcKryxbip165dhkIEst2jR5HLln89a84kSGFaDtWu7eDvH7BnzxZIx+C3f7diYaVyBzx/cNbAJYx+8ezcX6c7ftwFXBYfHz8o5qHGCAb81u3r9+7dBmNAmRDI0OCxbtu28eq/lyLu3ITKTmZGutK3pQiZuwRKVXB60HtCvfYE533OMwUVbnCO+vT9HxRvIlEp+CxIR6CANBWYjh4TPHxkvxbNW48fPxV2+w8MTE1LQf+Zxo2bbtvyCzQw9B8YNCdkMpjo75avBwdT+yFovWjQwH/CpGG9+nSE3NyzR1/l9zKJRDwoeBi0Fgd2azNr9kRIqfAGILxrl+5QD9q7bzu8h6NHD0yfFhIU2BPqrut/WAmihq4NJ2XkN0vmhsybaioUrlr5Y6VFW8zNzZcsXn3r1jVoREHvA/Xj8X5engA2f+BXnojlA2ff8pgGra07f1a76iEN+R4Z0NdjqUl0/pYjU8ycgD5YoGxesPArTUf37ztBta7gAJTdhM59tj5k5OX0tgOajuIjPKKcfNy+4To7uSAWpLDhGo6wfbaYj25tO4ohWay3xxB0zPcyVFNTH7HQBmvz8YXVnuHoNS6HhRFoadvR2J7PjsthPJp8Pd3a9c7+ddTG5j33LGDRBHzYbN60fTUjy6cR1uDpa2jT1bGrpkhU0qBBPcRSI5iZCaofWSb/WKc+G7+f8r5Llx4W5uy8qzUEKSurfmSDt+dbmrMGv+bgEvzqR9ZiwjX312Ob9ZiOprGYrPTMR4OvR7LN+cyHbdthOrj13WB5i66+HgsOaGjTJdg5VRkCQUr7cPEAABAASURBVOjYd0Pu5svYBn0mINOnzxYrPdNhy3uGw36/xxedx2ZwuEj9EissDELTGGx50x4Ls2FtPr7QvAhexJ2b/QYEaonw8OH9FyrzGBiOc+dOF+g+nQc1Y1tcXEx1IpeWli79dl7nri237whDNYbmNl2atW/Vsu2JY39rifDjpjUSsRgZmJyc7LDwUHOVSXKqSUxstEAg8PKq1uSc9+7djnr84Py5m1+Mn4pqDF3bdAlIEjVS3k+bMS4osOenfQZOmTamTesO169fkUgltWs7Tps618XZdfLU0S9fJmzdvnHUyAneXr7rf1gZnxAL79rTw3vihBkODo63bl8P37y+fv1G8XExG3/cOXvul/6NAiIj73Tu3M3R0XnHzp9+2XeCutGQob1nTJvXrt3Hk74c0cg/IC8359mzx+4eXmPHfCngC0LmT+VyebPmTFqx/Adzcx1SwPPnT/zq1P9uxcJLl8/71ak3dOiY/3WSm7FNP4VGRNwQmgrNzS3gFv7+AX+eOblzVziXy50TMjl0bfj9yDsHD+4pKSmWSqU9e/br13cQnAX2IC0tJSMz3cnReeGC76peBOkBobGphqPxjBoZgR8T89zPrz40I8bHx8B26Pebd2w7iOQW+BT87d2rv6+P34b125o1bblx01pra5uwjbu2hO8zMzMPXbccIiQnJeZkZw0eNGLb1l9MTU1fJsYXFORv3bJ/yOCRcLW6fvWpu+QX5Kenp9Wr15AkycSX8XwT/qKFK/bsPgK7R44e8PDwCgho0b1bb7iRqvDLln8N9ln1n3K2ZCWgfebrjGFDx57981r79h1/Usy8ePL3I0+fRq1csQGeBC47f8F0kUjUs0dfL0+fzwYNh7vA0RUrF02YMH1z+F75k/y8Fco+pJhmJyExbu3qMBBe7UWQ7hCaNdbQd0M+4b7BG/YSE+Ph90B2efUqCTbmzFlsoZhiD4w8NeEYWNQ6deRdQB89irxx8yq8LJCfx+N16hQYG/eCitCm7Uc+PvIp+UDdwqLCYdQki4pDfm+0f/HiWa1a9nZ2tZKTX3I4HLAiSDEjXL26DajJriCh1PGtW+nxvlm86tKFO6r/du88XCnO8+gncDVfXz+wRs2btYarFRcXb9+xCbKpm6t89enAwB5FRUXp6amwHR39FIwEbGzfGdb302BqulhIeZC+qbmZ4uJeDOg/RCgUarmIrhjpPNrwLkA20ODZ8yc+3nWsLK2ocLDGwcHDkEKSLp27wwZYSHCUPu3bWXkuNQ1h9IunlJDys54/Bg1cXdyoXTg3eOBQ5TaVDl7IjUEDaiJe4PXrTEhM4K/Fx8cqE0r1gUcCL6916/Lu0q+z5FeDe4FOc0OmqMa0sLBMTUuBpAm2B24XFfVgyuTZyqO5eTlWVtZ5ebkpqa+o+dw0XQS9VzS07fAIJEGGRp41FfkA8qXvm2wHesA7aqCYqxTCJ34hnzi1rEwUFNRzwfxlqqfDqwfNQEtqF1JSHd/yfuJZWa+zs7OUWflRVCRl/2Njoy3fpDBqRk156aDw15RzWioBmw+luGoI+HSqWR8MvnyC1DcznoGJbhrQQlQmcnR0OnTgdKWr/XP1oouLfM4+eGwwquBkUOF5+Xlg/xr7N4UM4OzkYqkQWNNF9EDntRNIiUxqeF8PpKVym2rZDIHgxIENgEQAr8lJMYWCt3edJ08eQc6A7SdPo9Z+v6ysrAxigmfu5ORMnQjaKy9CTedHzYIH7/Tu3Vt+b7QHu0rN9nbh4rmiosJOHQOTkhIdHJyqTmr4TpsPBh8yMUiOFEn2wsWzfXoPBJ8UUl60Yn7VtLTUHzeuoeYTVP5GkN/T0/t2xHWkqCKuX7+iebNWkPLkabdOedrVdBE9MFKbD+JBkYYqmu4Xb+wz2M/atR3APwfnrvP/grKyMsd9AWWhWWlpybyQpXw+Xy62yky6YPNHDB9Pbbu5eQwKHjZ/wQxw/WAD8pm3Ypre59FPx42dPHb8Z+Dugd6rVv4Izh286JSU5IGDuh85fFanqeUePro/9PPR4IQWg7sukXw5aWZAQHMIX/5tKLhycKmMjLTRoya6u3tSvwvqINSJECEsfN3Jk7+BEQIjD2U8oryBN2nX3r622ou8X9TPsbZ3eQI06w6c6YUYRGZmxuDPe507c52aux0T9i6Lqd/auutgNXOsaei7QegzQbHaRWI0zRHbv/9gS4saHcoDZgZyD1bCa0fjvBt61O5HjhiPjBjw6ZQTtLMgrL7lGHnSrHnU+/kcDkGw8+0wBR37apLsqCyGIM/GGhp1Nc2pitjOmsyAJGWkhqYatu8GvrDa4wurPb6w2jMcnb/lcHiIQ3NvLpb3g87fckgJ20eb+bA2H1+0tOshFmajoe8GyTbrMR/W5uOLeu35JoSEZI0+E1BU2dQvQKze5gssCFKi24rFLMYJIUN2Turn4VSvfUBHy+ICVvsPnrhHOVC5D/jYTu1R9dr7NrG1sOUd/TEOsXzIXD+d5RdgpukoocWhP/5TclZKacD/atVvbYtYPihun0uPvlPQcaB9ozYaF4IktFfmjocnpSeWSSUavwFXQD5Tu9xDVDtBm3wK/yqhVWNWY3I3mZa+BcrVXKvejtA8d5giLoHUPYPG51H8Vu3R1F6nQqC6R1J/xyo/mpoGT1YlPrTewzUFpkT9VhYf93NEmiGqU5EvySkpLOFWDecgglS5r8rP48iqjOPlyAiSkFX6tdCGRFZ8AI6MQxKklhtRV6g0UJhKcZSA5c/AIWSqDdny3itvAxRDTWXbt21v5N+offv2XA4hJVV/yNvnr/Qb4c1SEQnFJUg1v13+LFRfV9X0x5URUsXwVuo9lMeUR5ApVCTenKIIUmxQ0lB35Cg6T8t/4JvfxVGkPEV248gULfDlzyZFtd2rNcl6ter3QluhkIlWv0CULLTyq+2iw3T0TILAuQGvtLSUpwBhCdbaYw7WX+nnzp1769YthCtYt+cXFhbi/L0S9/Kez+dzcO2ixJb3+IJ1eT9hwoRnz54hXMG6vC8oKMDW4CO2vBcIBNi6e2x5jy9Yl/fBwcHp6ekIV3Cv37PlPaaw5T1b3mMK1uV9UFAQZH2EK7jX77lcLsIVrG1+SUmJUChEuMKW9/iCb3kPJT2U9whj8C3vxQoQxuBr8+GHi0Qi5ToKGMKW9/iCb3kPLflff/01whh8y3toyb9//z7CGNzb89nyngVH8C3vi4uLu3fvjjAG3/Kex+Pl5+cjjGHb89n2fBb8wPr7fZcuXSQSw6//aaxgrT2055eVlSFcYct7trxnwQ+sbX7//v1fv36NcAXr/nrg6LHlPaaw/fPZ8h5TsC7vR48eHRsbi3AF6/JeKpWKRCKEKzja/KCgIC6XC8JLFFAtPK6urqdOnUI4gWO+t7CwSEpKUg0xNTUF+48wA8fyPjg4uNLQa2dnZ6jrI8zAUfuhQ4e6ubkpd+FDfr9+/TAciI+j9lChHzFiBNTsqV1IBwMGDED4gWkdDyy8p6cnUqSDHj16mJubI/zAt34/cuRI+Ijn4eHRt29fhCXGXsd7cCXn+d38vGypWETKSPlSAWqeV91CGuoXsihfqeBd51ZZzqJqrKpx5KspEPI1yQSmHFsHk2ZdbLwaWCIjxni1P/zDy8ykMnjlPAHX1JJvbmMqsDQh+CZc1edVKCxf2IJTMegNlTWTKZbEULlC+TIvMsUqGKrRKG0JjYuivFkf5i2kFD4OiUvyRSU5IlFRmVRMcnmEd2Pz7sOdkFFijNr/sTMl4XExl8+p7WNTy90afbCkPMvMSy2CN9y2h13zLnbIyDA67bcviJNIkVtAbUtbM8QIMmKzMxPybGubDJ3niYwJ49I+fE6MeS0zz6aOiHG8uJ5EyMjx3/kgo8GItA+bFePSyM7O5QM28tp5cSPJhCcb/Y03Mg6MpY4XNjPGtQmThQf82rlLCc7meTHIODAK7beExFo6mdk6Mll4Ct+WbtCadOD7RGQE0K/9sfBkxCU8mzCwjFdL/U5eOenip7fzEN3Qr33Ki9I67V0RTlg7WV45lonohmbtD4Um8s2xW53QrZG9VIxu/Elz93CatX+dInaua3SNHkq+3/T50VNrkQEwsxM+ukaz2adT+6snMjhcZFkbx29o3s2dyoplZLWWFzcUdGof96jIxBTfzqIEF138lc5VO+h89cUFpJWToTK9VCo58/eWp9HXcnPTvD0D2rcZ1LBeB+rQklXdu3edUFSc+9fFHQK+sJ5f2749ZllZ2cOhtIy4Q0eXpWfG1/FpEdhpLDIkXBNOajydM7jTme+lYplVbUM12h8/HXr1xsGP2gxaMPtE40Zd9h6a/zDqInWIyzW5/O9+guAs+/qvkOmH4xMfnLu0HcmHaIl37P3KxtohZPqvvbpNhTgFBQZ0x0wtBCUFdDaq0uzrWdobJN+LxaI7kX90+XhUu9YDzM2s27T4tFmT7ucv71RGsLdzC+w0Rii0hOxer07b5FfyFRIfPbmUm5f+aY+ZtjZOTg4+/XvPKSktQAaDL+RJyrAs70sKDDjhRVLKU4mkrG6dNsoQX6/mqekxRcXlrrWbawPlIaHQqlRUCBuvs5L4JqZ2ts5UuJWlvY21AVucODxCTb+RGoS28p7PM+DPLi2Ra/nTjgmVwgsKs8AMKDbV3L24JJ8vqFAGmfAMOPMifETj0LpoB23ac4Xy311SWCq0eP/vl3Lcgvt+bW/nrhpua62tC42Z0EokKlYNKRUVIYMhLpVyeVjmeyQ3eqggs9gQ2teu5WFiIu+CDe46FVJQmA1fqwUCba6lrY2zWFwKRYOzYx3YfZUanV9gwJbXspIyU3M6tafT1zM14xZlGaSSAxp36/zF+Us74xIjxZIy8PC37Zl27PQ7WugaNejI4/F/O7GqrKw0Lz9z/+FFZmYG/LQoKZXaOPARfdCZ7x08+MkvDDUMtvPHI1yc6166uvdFbISpqYWXe+NBfRdoP0VoajFu+Po//gpbtKILOH1Qzbv38JzhMiY4+QGd6OzIS2e/nbKysm3zX/oHGUs/lpokNTor71XBpLW+iD7otPl8Pt/cihsXkYrwIy+lwK2uANEKzc3p7XrbXTykzZ/a/vOMxOQotYeg1ZbLVf/8QwZ849+gE3pPXPzn54tX96o9JBRYlCjaBqoyedwWFyc/tYdy0golYlnv8W6IVujvq7n723hE8Lxbuag9mp//WiJVPxVWmVjEN1GfdSzM7fj891Z9KCkp0NTAB16hphtZWdbm8UzUHnp2OcGjgbDnaPU/ucYwin66YbNiPFs4WtoxpEO+dhIi08SFoi9W0N9Z2yj6anb+rNbLe3R+zawxCrKKi16XGIPwyEi0b9TWtklHq6i/4hGjkZRJEu+mT1prLPUaIxqb8TK6+PS2FN/2rgIhnS0eBiItJut1XP6Xod7Gs/K2cY3Junsh++Yf2eZ2pl4tnBGDeHHtpVRMTlpDZ22+KsY4DnfbgtiyUpl0j0XiAAAA80lEQVS1k5l74w++035cxKuSvDJbR5OhIcY1EBMZ7fj7a6czH/6TJxUjEyHX0t7M1tNSaEZzS0j1Kcguzn1VUJRdCnndzIobOKS2ez0LZHwY9bwbz+7mRZzPLcwSSyWI4Ci+uXMIVKHPx5vJFRRTI1SeaaE8UD6HgmqgfPINlbPKoxHy/6meqH5DedOqE3vI592QyUj5homAsHcRdBlib2NvvGsvfjDzasY8yM9JF4uKSVKqElpRgKpzYWgILD9N9s5+MwSBqv1+oI3RzJpj7yp09/swGirYebTxBeu5lDGH1R5fWO3xhdUeX1jt8YXVHl/+DwAA//+6cZoRAAAABklEQVQDAGhc0BnIBQ6JAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6bd1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"the benefits of adopting Langgraph as an agent framework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca5b3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_analysts = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e3850f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread =  {\"configurable\":{\"thread_id\":1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe662e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alice Chen\n",
      "Affiliation: TechForward Innovations\n",
      "Role: Lead AI Architect\n",
      "Description: Focuses on the architectural benefits of Langgraph, particularly its modularity and scalability for complex agent systems. She is motivated by building robust and maintainable AI solutions.\n",
      "--------------------------------------------------\n",
      "Name: Bob Johnson\n",
      "Affiliation: Sentinel AI Ethics Institute\n",
      "Role: AI Risk Management Officer\n",
      "Description: Concerned with the safety and ethical implications of Langgraph, especially regarding its use in autonomous agents. He seeks to ensure responsible development and deployment of AI systems.\n",
      "--------------------------------------------------\n",
      "Name: Charlie Davis\n",
      "Affiliation: QuantumLeap AI Research Lab\n",
      "Role: AI Research Scientist\n",
      "Description: Interested in Langgraph's potential for advancing AI research, particularly in areas like multi-agent collaboration and complex reasoning. He aims to explore the framework's capabilities and push the boundaries of AI.\n",
      "--------------------------------------------------\n",
      "Name: Diana Rodriguez\n",
      "Affiliation: Global AI Solutions\n",
      "Role: AI Solutions Consultant\n",
      "Description: Focuses on the practical applications of Langgraph for solving real-world business problems. She is motivated by demonstrating the value and ROI of AI solutions to clients.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"topic\":topic,\"max_analysts\":max_analysts},\n",
    "             thread,\n",
    "             stream_mode= \"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "    \n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)  \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7b08aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63c172ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'the benefits of adopting Langgraph as an agent framework', 'max_analysts': 4, 'analysts': [Analyst(name='Alice Chen', role='Lead AI Architect', affiliation='TechForward Innovations', description='Focuses on the architectural benefits of Langgraph, particularly its modularity and scalability for complex agent systems. She is motivated by building robust and maintainable AI solutions.'), Analyst(name='Bob Johnson', role='AI Risk Management Officer', affiliation='Sentinel AI Ethics Institute', description='Concerned with the safety and ethical implications of Langgraph, especially regarding its use in autonomous agents. He seeks to ensure responsible development and deployment of AI systems.'), Analyst(name='Charlie Davis', role='AI Research Scientist', affiliation='QuantumLeap AI Research Lab', description=\"Interested in Langgraph's potential for advancing AI research, particularly in areas like multi-agent collaboration and complex reasoning. He aims to explore the framework's capabilities and push the boundaries of AI.\"), Analyst(name='Diana Rodriguez', role='AI Solutions Consultant', affiliation='Global AI Solutions', description='Focuses on the practical applications of Langgraph for solving real-world business problems. She is motivated by demonstrating the value and ROI of AI solutions to clients.')]}, next=('human_feedback',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0caa91-e00c-6c5e-8001-9efba8bec80f'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-11-26T09:20:15.013795+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0caa91-c364-6ea4-8000-766a932be3e9'}}, tasks=(PregelTask(id='c9bbb0f1-6ff4-181a-3632-aff11bd14be4', name='human_feedback', path=('__pregel_pull', 'human_feedback'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d2a5eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'the benefits of adopting Langgraph as an agent framework',\n",
       " 'max_analysts': 4,\n",
       " 'analysts': [Analyst(name='Alice Chen', role='Lead AI Architect', affiliation='TechForward Innovations', description='Focuses on the architectural benefits of Langgraph, particularly its modularity and scalability for complex agent systems. She is motivated by building robust and maintainable AI solutions.'),\n",
       "  Analyst(name='Bob Johnson', role='AI Risk Management Officer', affiliation='Sentinel AI Ethics Institute', description='Concerned with the safety and ethical implications of Langgraph, especially regarding its use in autonomous agents. He seeks to ensure responsible development and deployment of AI systems.'),\n",
       "  Analyst(name='Charlie Davis', role='AI Research Scientist', affiliation='QuantumLeap AI Research Lab', description=\"Interested in Langgraph's potential for advancing AI research, particularly in areas like multi-agent collaboration and complex reasoning. He aims to explore the framework's capabilities and push the boundaries of AI.\"),\n",
       "  Analyst(name='Diana Rodriguez', role='AI Solutions Consultant', affiliation='Global AI Solutions', description='Focuses on the practical applications of Langgraph for solving real-world business problems. She is motivated by demonstrating the value and ROI of AI solutions to clients.')]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e772e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human_feedback',)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140be2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "231450e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('1', defaultdict(<class 'dict'>, {'': {'1f0caa91-c355-6fca-bfff-99ec1ebf15b4': (('msgpack', b'\\x86\\xa1v\\x04\\xa2ts\\xd9 2025-11-26T09:20:12.002913+00:00\\xa2id\\xd9$1f0caa91-c355-6fca-bfff-99ec1ebf15b4\\xb0channel_versions\\x81\\xa9__start__\\xd9300000000000000000000000000000001.0.9811121883026522\\xadversions_seen\\x81\\xa9__input__\\x80\\xb0updated_channels\\x91\\xa9__start__'), ('msgpack', b'\\x83\\xa6source\\xa5input\\xa4step\\xff\\xa7parents\\x80'), None), '1f0caa91-c364-6ea4-8000-766a932be3e9': (('msgpack', b'\\x86\\xa1v\\x04\\xa2ts\\xd9 2025-11-26T09:20:12.009027+00:00\\xa2id\\xd9$1f0caa91-c364-6ea4-8000-766a932be3e9\\xb0channel_versions\\x84\\xa9__start__\\xd9300000000000000000000000000000002.0.6148614229258239\\xa5topic\\xd9300000000000000000000000000000002.0.6148614229258239\\xacmax_analysts\\xd9300000000000000000000000000000002.0.6148614229258239\\xb8branch:to:create_analyst\\xd9300000000000000000000000000000002.0.6148614229258239\\xadversions_seen\\x82\\xa9__input__\\x80\\xa9__start__\\x81\\xa9__start__\\xd9300000000000000000000000000000001.0.9811121883026522\\xb0updated_channels\\x93\\xb8branch:to:create_analyst\\xacmax_analysts\\xa5topic'), ('msgpack', b'\\x83\\xa6source\\xa4loop\\xa4step\\x00\\xa7parents\\x80'), '1f0caa91-c355-6fca-bfff-99ec1ebf15b4'), '1f0caa91-e00c-6c5e-8001-9efba8bec80f': (('msgpack', b'\\x86\\xa1v\\x04\\xa2ts\\xd9 2025-11-26T09:20:15.013795+00:00\\xa2id\\xd9$1f0caa91-e00c-6c5e-8001-9efba8bec80f\\xb0channel_versions\\x86\\xa9__start__\\xd9300000000000000000000000000000002.0.6148614229258239\\xa5topic\\xd9300000000000000000000000000000002.0.6148614229258239\\xacmax_analysts\\xd9300000000000000000000000000000002.0.6148614229258239\\xb8branch:to:create_analyst\\xd9300000000000000000000000000000003.0.6594971460681561\\xa8analysts\\xd9300000000000000000000000000000003.0.6594971460681561\\xb8branch:to:human_feedback\\xd9300000000000000000000000000000003.0.6594971460681561\\xadversions_seen\\x83\\xa9__input__\\x80\\xa9__start__\\x81\\xa9__start__\\xd9300000000000000000000000000000001.0.9811121883026522\\xaecreate_analyst\\x81\\xb8branch:to:create_analyst\\xd9300000000000000000000000000000002.0.6148614229258239\\xb0updated_channels\\x92\\xa8analysts\\xb8branch:to:human_feedback'), ('msgpack', b'\\x83\\xa6source\\xa4loop\\xa4step\\x01\\xa7parents\\x80'), '1f0caa91-c364-6ea4-8000-766a932be3e9')}}))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.storage.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4747e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import msgpack\n",
    "\n",
    "# for thread_id, ns_dict in memory.storage.items():\n",
    "#     print(f\"\\n Thread ID: {thread_id}\")\n",
    "    \n",
    "#     # ns_dict = defaultdict(dict, {'': {...}})\n",
    "#     for ns, ckpts in ns_dict.items():\n",
    "#         print(f\"  Namespace: '{ns}'\")\n",
    "        \n",
    "#         # ckpts = dict of {checkpoint_id: (packed_values, packed_metadata, parent_id)}\n",
    "#         for ckpt_id, (packed_values, packed_metadata, parent_id) in ckpts.items():\n",
    "#             print(f\"    Checkpoint ID: {ckpt_id}\")\n",
    "            \n",
    "#             # Decode msgpack binary\n",
    "#             values = msgpack.unpackb(packed_values[1], raw=False)\n",
    "#             meta = msgpack.unpackb(packed_metadata[1], raw=False)\n",
    "            \n",
    "#             print(f\"    Values keys: {list(values.keys())}\")\n",
    "#             print(f\"    Parent ID: {parent_id}\")\n",
    "#             print(f\"    Metadata: {meta}\")\n",
    "#             print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a867143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0caa91-e00c-6c5e-8001-9efba8bec80f'}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb7d8558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0caa93-ca1f-658d-8002-eb232d39eb61'}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(thread,\n",
    "                   {\"human_analyst_feedback\":\"add something from the startup perspective and focus on the latest enterprise application\"},as_node=\"human_feedback\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92f6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alice Chen\n",
      "Affiliation: TechForward Innovations\n",
      "Role: Lead AI Architect\n",
      "Description: Focuses on the architectural benefits of Langgraph, particularly its modularity and scalability for complex agent systems. She is motivated by building robust and maintainable AI solutions.\n",
      "--------------------------------------------------\n",
      "Name: Bob Johnson\n",
      "Affiliation: Sentinel AI Ethics Institute\n",
      "Role: AI Risk Management Officer\n",
      "Description: Concerned with the safety and ethical implications of Langgraph, especially regarding its use in autonomous agents. He seeks to ensure responsible development and deployment of AI systems.\n",
      "--------------------------------------------------\n",
      "Name: Charlie Davis\n",
      "Affiliation: QuantumLeap AI Research Lab\n",
      "Role: AI Research Scientist\n",
      "Description: Interested in Langgraph's potential for advancing AI research, particularly in areas like multi-agent collaboration and complex reasoning. He aims to explore the framework's capabilities and push the boundaries of AI.\n",
      "--------------------------------------------------\n",
      "Name: Diana Rodriguez\n",
      "Affiliation: Global AI Solutions\n",
      "Role: AI Solutions Consultant\n",
      "Description: Focuses on the practical applications of Langgraph for solving real-world business problems. She is motivated by demonstrating the value and ROI of AI solutions to clients.\n",
      "--------------------------------------------------\n",
      "Name: Ava Chen\n",
      "Affiliation: InnovateAI\n",
      "Role: Startup CTO\n",
      "Description: Focuses on Langgraph's rapid prototyping and iteration capabilities for startups. Concerned with minimizing development overhead and maximizing agility in a competitive market. Motivated by faster time-to-market and efficient resource allocation.\n",
      "--------------------------------------------------\n",
      "Name: Raj Patel\n",
      "Affiliation: GlobalTech Solutions\n",
      "Role: Enterprise AI Architect\n",
      "Description: Focuses on Langgraph's scalability and integration within existing enterprise systems. Concerned with security, compliance, and governance when deploying AI solutions. Motivated by robust performance and seamless integration with legacy infrastructure.\n",
      "--------------------------------------------------\n",
      "Name: Lena Meyer\n",
      "Affiliation: FutureAI Labs\n",
      "Role: AI Research Scientist\n",
      "Description: Focuses on Langgraph's potential for advancing AI research and development. Concerned with pushing the boundaries of agentic AI and exploring novel applications. Motivated by innovation and contributing to the cutting edge of AI technology.\n",
      "--------------------------------------------------\n",
      "Name: Kenji Tanaka\n",
      "Affiliation: DataWise Inc.\n",
      "Role: AI Product Manager\n",
      "Description: Focuses on Langgraph's user experience and productization aspects. Concerned with ease of use, accessibility, and practical applications for end-users. Motivated by creating user-friendly AI products that solve real-world problems.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"topic\":topic,\n",
    "              \"max_analysts\":max_analysts},\n",
    "             thread,\n",
    "             stream_mode= \"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "    \n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "655163ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ffc316df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'the benefits of adopting Langgraph as an agent framework', 'max_analysts': 4, 'human_analyst_feedback': 'add something from the startup perspective and focus on the latest enterprise application', 'analysts': [Analyst(name='Ava Chen', role='Startup CTO', affiliation='InnovateAI', description=\"Focuses on Langgraph's rapid prototyping and iteration capabilities for startups. Concerned with minimizing development overhead and maximizing agility in a competitive market. Motivated by faster time-to-market and efficient resource allocation.\"), Analyst(name='Raj Patel', role='Enterprise AI Architect', affiliation='GlobalTech Solutions', description=\"Focuses on Langgraph's scalability and integration within existing enterprise systems. Concerned with security, compliance, and governance when deploying AI solutions. Motivated by robust performance and seamless integration with legacy infrastructure.\"), Analyst(name='Lena Meyer', role='AI Research Scientist', affiliation='FutureAI Labs', description=\"Focuses on Langgraph's potential for advancing AI research and development. Concerned with pushing the boundaries of agentic AI and exploring novel applications. Motivated by innovation and contributing to the cutting edge of AI technology.\"), Analyst(name='Kenji Tanaka', role='AI Product Manager', affiliation='DataWise Inc.', description=\"Focuses on Langgraph's user experience and productization aspects. Concerned with ease of use, accessibility, and practical applications for end-users. Motivated by creating user-friendly AI products that solve real-world problems.\")]}, next=('human_feedback',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0caa94-33e1-6c83-8005-159c25d105c0'}}, metadata={'source': 'loop', 'step': 5, 'parents': {}}, created_at='2025-11-26T09:21:17.491315+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0caa94-15f2-67f1-8004-7b0a08d0a05c'}}, tasks=(PregelTask(id='66a4088f-c215-9feb-7121-57506e94548c', name='human_feedback', path=('__pregel_pull', 'human_feedback'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "055b0545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human_feedback',)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f86148ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'the benefits of adopting Langgraph as an agent framework',\n",
       " 'max_analysts': 4,\n",
       " 'human_analyst_feedback': 'add something from the startup perspective and focus on the latest enterprise application',\n",
       " 'analysts': [Analyst(name='Ava Chen', role='Startup CTO', affiliation='InnovateAI', description=\"Focuses on Langgraph's rapid prototyping and iteration capabilities for startups. Concerned with minimizing development overhead and maximizing agility in a competitive market. Motivated by faster time-to-market and efficient resource allocation.\"),\n",
       "  Analyst(name='Raj Patel', role='Enterprise AI Architect', affiliation='GlobalTech Solutions', description=\"Focuses on Langgraph's scalability and integration within existing enterprise systems. Concerned with security, compliance, and governance when deploying AI solutions. Motivated by robust performance and seamless integration with legacy infrastructure.\"),\n",
       "  Analyst(name='Lena Meyer', role='AI Research Scientist', affiliation='FutureAI Labs', description=\"Focuses on Langgraph's potential for advancing AI research and development. Concerned with pushing the boundaries of agentic AI and exploring novel applications. Motivated by innovation and contributing to the cutting edge of AI technology.\"),\n",
       "  Analyst(name='Kenji Tanaka', role='AI Product Manager', affiliation='DataWise Inc.', description=\"Focuses on Langgraph's user experience and productization aspects. Concerned with ease of use, accessibility, and practical applications for end-users. Motivated by creating user-friendly AI products that solve real-world problems.\")]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0540c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import msgpack\n",
    "\n",
    "# def get_all_checkpoints(memory, thread_id=\"1\"):\n",
    "#     \"\"\"Return all checkpoints in chronological order for a thread.\"\"\"\n",
    "#     checkpoints = []\n",
    "#     ns_dict = memory.storage.get(thread_id, {})\n",
    "#     if \"\" not in ns_dict:\n",
    "#         return []\n",
    "\n",
    "#     for ckpt_id, (packed_values, packed_meta, parent_id) in ns_dict[\"\"].items():\n",
    "#         values = msgpack.unpackb(packed_values[1], raw=False)\n",
    "#         meta = msgpack.unpackb(packed_meta[1], raw=False)\n",
    "#         checkpoints.append({\n",
    "#             \"id\": ckpt_id,\n",
    "#             \"parent\": parent_id,\n",
    "#             \"topic\": values.get(\"topic\"),\n",
    "#             \"feedback\": values.get(\"human_analyst_feedback\"),\n",
    "#             \"analyst_count\": len(values.get(\"analysts\", [])),\n",
    "#             \"analysts\": [a.model_dump() for a in values.get(\"analysts\", [])],\n",
    "#             \"step\": meta.get(\"step\"),\n",
    "#             \"created_at\": values.get(\"ts\", None)\n",
    "#         })\n",
    "#     return checkpoints\n",
    "\n",
    "# # Fetch all\n",
    "# history = get_all_checkpoints(memory)\n",
    "\n",
    "# # Sort by step (to get chronological order)\n",
    "# history = sorted(history, key=lambda x: (x[\"step\"] or 0))\n",
    "\n",
    "# # Display neatly\n",
    "# for h in history:\n",
    "#     print(f\"\\nSTEP {h['step']} | CHECKPOINT {h['id']}\")\n",
    "#     print(f\"Parent: {h['parent']}\")\n",
    "#     print(f\"Topic: {h['topic']}\")\n",
    "#     print(f\"Feedback: {h['feedback']}\")\n",
    "#     print(f\"Analysts generated: {h['analyst_count']}\")\n",
    "#     print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a17375c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are satisfied, then we simply supply no feedback\n",
    "further_feedack = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7cac0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get the latest state (you're paused at 'human_feedback')\n",
    "state = graph.get_state(thread)\n",
    "\n",
    "# 2) Use the exact config from that state (it already has thread_id, checkpoint_ns, checkpoint_id)\n",
    "cfg = state.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82420b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0caa97-f3a5-64d6-8006-d0e585618d7f'}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Update feedback at the 'human_feedback' node\n",
    "#    Tip: if your TypedDict says `human_analyst_feedback: str`, prefer \"\" (empty string) over None\n",
    "graph.update_state(cfg, {\"human_analyst_feedback\": \"\"}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aceb37c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# 4) Verify it moved to END\n",
    "final_state = graph.get_state(thread)\n",
    "print(final_state.next)  # should be (END,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "763cb15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysts = final_state.values.get('analysts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e26234f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Analyst(name='Ava Chen', role='Startup CTO', affiliation='InnovateAI', description=\"Focuses on Langgraph's rapid prototyping and iteration capabilities for startups. Concerned with minimizing development overhead and maximizing agility in a competitive market. Motivated by faster time-to-market and efficient resource allocation.\"),\n",
       " Analyst(name='Raj Patel', role='Enterprise AI Architect', affiliation='GlobalTech Solutions', description=\"Focuses on Langgraph's scalability and integration within existing enterprise systems. Concerned with security, compliance, and governance when deploying AI solutions. Motivated by robust performance and seamless integration with legacy infrastructure.\"),\n",
       " Analyst(name='Lena Meyer', role='AI Research Scientist', affiliation='FutureAI Labs', description=\"Focuses on Langgraph's potential for advancing AI research and development. Concerned with pushing the boundaries of agentic AI and exploring novel applications. Motivated by innovation and contributing to the cutting edge of AI technology.\"),\n",
       " Analyst(name='Kenji Tanaka', role='AI Product Manager', affiliation='DataWise Inc.', description=\"Focuses on Langgraph's user experience and productization aspects. Concerned with ease of use, accessibility, and practical applications for end-users. Motivated by creating user-friendly AI products that solve real-world problems.\")]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "753e9a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Ava Chen\n",
      "Affiliation: InnovateAI\n",
      "Role: Startup CTO\n",
      "Description: Focuses on Langgraph's rapid prototyping and iteration capabilities for startups. Concerned with minimizing development overhead and maximizing agility in a competitive market. Motivated by faster time-to-market and efficient resource allocation.\n",
      "--------------------------------------------------\n",
      "Name: Raj Patel\n",
      "Affiliation: GlobalTech Solutions\n",
      "Role: Enterprise AI Architect\n",
      "Description: Focuses on Langgraph's scalability and integration within existing enterprise systems. Concerned with security, compliance, and governance when deploying AI solutions. Motivated by robust performance and seamless integration with legacy infrastructure.\n",
      "--------------------------------------------------\n",
      "Name: Lena Meyer\n",
      "Affiliation: FutureAI Labs\n",
      "Role: AI Research Scientist\n",
      "Description: Focuses on Langgraph's potential for advancing AI research and development. Concerned with pushing the boundaries of agentic AI and exploring novel applications. Motivated by innovation and contributing to the cutting edge of AI technology.\n",
      "--------------------------------------------------\n",
      "Name: Kenji Tanaka\n",
      "Affiliation: DataWise Inc.\n",
      "Role: AI Product Manager\n",
      "Description: Focuses on Langgraph's user experience and productization aspects. Concerned with ease of use, accessibility, and practical applications for end-users. Motivated by creating user-friendly AI products that solve real-world problems.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for analyst in analysts:\n",
    "    print(f\"Name: {analyst.name}\")\n",
    "    print(f\"Affiliation: {analyst.affiliation}\")\n",
    "    print(f\"Role: {analyst.role}\")\n",
    "    print(f\"Description: {analyst.description}\")\n",
    "    print(\"-\" * 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c15bce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The benefits of adopting LangGraph as an agent framework'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"The benefits of adopting LangGraph as an agent framework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c36ad6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "== History ==\n",
      "LangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "docs = WikipediaLoader(query=\"LangGraph\").load()\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9f6ef",
   "metadata": {},
   "source": [
    "Either you can use Google Serper API or use duckduckgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8520f4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud computing is defined by the ISO as \"a paradigm for enabling network access to a scalable and elastic pool of shareable physical or virtual resources with self-service provisioning and administration on demand\". It is commonly referred to as \"the cloud\".\n",
      "\n",
      "\n",
      "== Characteristics ==\n",
      "In 2011, the National Institute of Standards and Technology (NIST) identified five \"essential characteristics\" for cloud systems. Below are the exact definitions according to NIST:\n",
      "\n",
      "On-demand self-service: \"A consume\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "docs = WikipediaLoader(query=\"The benefits of adopting AWS Cloud\").load()\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db3f5002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'title': 'Cloud computing', 'summary': 'Cloud computing is defined by the ISO as \"a paradigm for enabling network access to a scalable and elastic pool of shareable physical or virtual resources with self-service provisioning and administration on demand\". It is commonly referred to as \"the cloud\".\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Cloud_computing'}, page_content='Cloud computing is defined by the ISO as \"a paradigm for enabling network access to a scalable and elastic pool of shareable physical or virtual resources with self-service provisioning and administration on demand\". It is commonly referred to as \"the cloud\".\\n\\n\\n== Characteristics ==\\nIn 2011, the National Institute of Standards and Technology (NIST) identified five \"essential characteristics\" for cloud systems. Below are the exact definitions according to NIST:\\n\\nOn-demand self-service: \"A consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with each service provider.\"\\nBroad network access: \"Capabilities are available over the network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, tablets, laptops, and workstations).\"\\nResource pooling: \" The provider\\'s computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to consumer demand.\"\\nRapid elasticity: \"Capabilities can be elastically provisioned and released, in some cases automatically, to scale rapidly outward and inward commensurate with demand. To the consumer, the capabilities available for provisioning often appear unlimited and can be appropriated in any quantity at any time.\"\\nMeasured service: \"Cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Resource usage can be monitored, controlled, and reported, providing transparency for both the provider and consumer of the utilized service.\\nBy 2023, the International Organization for Standardization (ISO) had expanded and refined the list.\\n\\n\\n== History ==\\n\\nThe history of cloud computing extends to the 1960s, with the initial concepts of time-sharing becoming popularized via remote job entry (RJE). The \"data center\" model, where users submitted jobs to operators to run on mainframes, was predominantly used during this era. This was a time of exploration and experimentation with ways to make large-scale computing power available to more users through time-sharing, optimizing the infrastructure, platform, and applications, and increasing efficiency for end users.\\nThe \"cloud\" metaphor for virtualized services dates to 1994, when it was used by General Magic for the universe of \"places\" that mobile agents in the Telescript environment could \"go\". The metaphor is credited to David Hoffman, a General Magic communications specialist, based on its long-standing use in networking and telecom. The expression cloud computing became more widely known in 1996 when Compaq Computer Corporation drew up a business plan for future computing and the Internet. The company\\'s ambition was to supercharge sales with \"cloud computing-enabled applications\". The business plan foresaw that online consumer file storage would likely be commercially successful. As a result, Compaq decided to sell server hardware to internet service providers.\\nIn the 2000s, the application of cloud computing began to take shape with the establishment of Amazon Web Services (AWS) in 2002, which allowed developers to build applications independently. In 2006 Amazon Simple Storage Service, known as Amazon S3, and the Amazon Elastic Compute Cloud (EC2) were released. In 2008 NASA\\'s development of the first open-source software for deploying private and hybrid clouds.\\nThe following decade saw the launch of various cloud services. In 2010, Microsoft launched Microsoft Azure, and Rackspace Hosting and NASA initiated an open-source cloud-software project, OpenStack. IBM introduced the IBM SmartCloud framework in 2011, and Oracle announced the Oracle Cloud in 2012. In December 2019, Amazon launched AWS Outposts'), Document(metadata={'title': 'Cloud computing issues', 'summary': 'Cloud computing enables users to access scalable and on-demand computing resources via the internet, utilizing hardware and software virtualization. It is a rapidly evolving technology capable of delivering extensible services efficiently, supporting a wide range of applications from personal storage solutions to enterprise-level systems. Despite its advantages, cloud computing also faces several challenges. Privacy concerns remain a primary issue, as users often lose direct control over their data once it is stored on servers owned and managed by cloud providers. This loss of control can create uncertainties regarding data privacy, unauthorized access, and compliance with regional regulations such as the General Data Protection Regulation (GDPR), the Health Insurance Portability and Accountability Act (HIPAA), and the California Consumer Privacy Act (CCPA). Service agreements and shared responsibility models define the boundaries of control and accountability between the cloud provider and the customer, but misunderstandings or mismanagement in these areas can still result in security breaches or accidental data loss. Cloud providers offer tools, such as AWS Artifact (compliance documentation and audits), Azure Compliance Manager (compliance assessments and risk analysis), and Google Assured Workloads (region-specific data compliance), to assist customers in managing compliance requirements. \\nSecurity issues in cloud computing are generally categorized into two broad groups. The first involves risks faced by cloud service providers, including vulnerabilities in their infrastructure, software, or third-party dependencies. The second includes risks faced by cloud customers, such as misconfigurations, inadequate access controls, and accidental data exposure. These risks are often amplified by human error or a lack of understanding of the shared responsibility model. Security responsibilities also vary depending on the service modelâ€”whether Infrastructure as a Service (IaaS), Platform as a Service (PaaS), or Software as a Service (SaaS). In general, cloud providers are responsible for hardware security, physical infrastructure, and software updates, while customers are responsible for data encryption, identity and access management (IAM), and application-level security. \\nAnother significant concern is uncertainty regarding guaranteed Quality of Service (QoS), particularly in multi-tenant environments where resources are shared among customers. Major cloud providers address these concerns through Service Level Agreements (SLAs), which define performance and uptime guarantees and often offer compensation in the form of service credits when guarantees are unmet. Automated management and remediation processes, supported by tools such as AWS CloudWatch, Azure Monitor, and Google Cloud Operations Suite, help detect and respond to large-scale failures. Despite these tools, managing QoS in highly distributed and multi-tenant systems remains complex. For latency-sensitive workloads, cloud providers have introduced edge computing solutions, such as AWS Wavelength, Azure Edge Zones, and Google Distributed Cloud Edge, to minimize latency by processing data closer to the end-user.  \\nJurisdictional and regulatory requirements regarding data residency and sovereignty introduce further complexity. Data stored in one region may fall under the legal jurisdiction of that region, creating potential conflicts for organizations operating across multiple geographies. Major cloud providers, such as AWS, Microsoft Azure, and Google Cloud, address these concerns by offering region-specific data centers and compliance management tools designed to align with regional regulations and legal frameworks.', 'source': 'https://en.wikipedia.org/wiki/Cloud_computing_issues'}, page_content='Cloud computing enables users to access scalable and on-demand computing resources via the internet, utilizing hardware and software virtualization. It is a rapidly evolving technology capable of delivering extensible services efficiently, supporting a wide range of applications from personal storage solutions to enterprise-level systems. Despite its advantages, cloud computing also faces several challenges. Privacy concerns remain a primary issue, as users often lose direct control over their data once it is stored on servers owned and managed by cloud providers. This loss of control can create uncertainties regarding data privacy, unauthorized access, and compliance with regional regulations such as the General Data Protection Regulation (GDPR), the Health Insurance Portability and Accountability Act (HIPAA), and the California Consumer Privacy Act (CCPA). Service agreements and shared responsibility models define the boundaries of control and accountability between the cloud provider and the customer, but misunderstandings or mismanagement in these areas can still result in security breaches or accidental data loss. Cloud providers offer tools, such as AWS Artifact (compliance documentation and audits), Azure Compliance Manager (compliance assessments and risk analysis), and Google Assured Workloads (region-specific data compliance), to assist customers in managing compliance requirements. \\nSecurity issues in cloud computing are generally categorized into two broad groups. The first involves risks faced by cloud service providers, including vulnerabilities in their infrastructure, software, or third-party dependencies. The second includes risks faced by cloud customers, such as misconfigurations, inadequate access controls, and accidental data exposure. These risks are often amplified by human error or a lack of understanding of the shared responsibility model. Security responsibilities also vary depending on the service modelâ€”whether Infrastructure as a Service (IaaS), Platform as a Service (PaaS), or Software as a Service (SaaS). In general, cloud providers are responsible for hardware security, physical infrastructure, and software updates, while customers are responsible for data encryption, identity and access management (IAM), and application-level security. \\nAnother significant concern is uncertainty regarding guaranteed Quality of Service (QoS), particularly in multi-tenant environments where resources are shared among customers. Major cloud providers address these concerns through Service Level Agreements (SLAs), which define performance and uptime guarantees and often offer compensation in the form of service credits when guarantees are unmet. Automated management and remediation processes, supported by tools such as AWS CloudWatch, Azure Monitor, and Google Cloud Operations Suite, help detect and respond to large-scale failures. Despite these tools, managing QoS in highly distributed and multi-tenant systems remains complex. For latency-sensitive workloads, cloud providers have introduced edge computing solutions, such as AWS Wavelength, Azure Edge Zones, and Google Distributed Cloud Edge, to minimize latency by processing data closer to the end-user.  \\nJurisdictional and regulatory requirements regarding data residency and sovereignty introduce further complexity. Data stored in one region may fall under the legal jurisdiction of that region, creating potential conflicts for organizations operating across multiple geographies. Major cloud providers, such as AWS, Microsoft Azure, and Google Cloud, address these concerns by offering region-specific data centers and compliance management tools designed to align with regional regulations and legal frameworks. \\n\\n\\n== Factors Influencing Adoption and Suitability of Cloud Computing ==\\nThe decision to adopt cloud computing or maintain on-premises infrastructure depends on factors such as scalability, cost structure, latency requirements, regulatory constraints, and infra'), Document(metadata={'title': 'Serverless computing', 'summary': 'Serverless computing is \"a cloud service category where the customer can use different cloud capability types without the customer having to provision, deploy and manage either hardware or software resources, other than providing customer application code or providing customer data. Serverless computing represents a form of virtualized computing,\" according to ISO/IEC 22123-2. Serverless computing is a broad ecosystem that includes the cloud provider, Function as a Service (FaaS), managed services, tools, frameworks, engineers, stakeholders, and other interconnected elements, according to Sheen Brisals.', 'source': 'https://en.wikipedia.org/wiki/Serverless_computing'}, page_content='Serverless computing is \"a cloud service category where the customer can use different cloud capability types without the customer having to provision, deploy and manage either hardware or software resources, other than providing customer application code or providing customer data. Serverless computing represents a form of virtualized computing,\" according to ISO/IEC 22123-2. Serverless computing is a broad ecosystem that includes the cloud provider, Function as a Service (FaaS), managed services, tools, frameworks, engineers, stakeholders, and other interconnected elements, according to Sheen Brisals.\\n\\n\\n== Overview ==\\nServerless is a misnomer in the sense that servers are still used by cloud service providers to execute code for developers.  The definition of serverless computing has evolved over time, leading to varied interpretations. According to Ben Kehoe, serverless represents a spectrum rather than a rigid definition. Emphasis should shift from strict definitions and specific technologies to adopting a serverless mindset, focusing on leveraging serverless solutions to address business challenges.\\nServerless computing does not eliminate complexity but shifts much of it from the operations team to the development team. However, this shift is not absolute, as operations teams continue to manage aspects such as identity and access management (IAM), networking, security policies, and cost optimization. Additionally, while breaking down applications into finer-grained components can increase management complexity, the relationship between granularity and management difficulty is not strictly linear. There is often an optimal level of modularization where the benefits outweigh the added management overhead.\\nAccording to Yan Cui, serverless should be adopted only when it helps to deliver customer value faster. And while adopting, organizations should take small steps and de-risk along the way.\\n\\n\\n== Challenges ==\\nServerless applications are prone to fallacies of distributed computing. In addition, they are prone to the following fallacies:\\n\\nVersioning is simple\\nCompensating transactions always work\\nObservability is optional\\n\\n\\n=== Monitoring and debugging ===\\nMonitoring and debugging serverless applications can present unique challenges due to their distributed, event-driven nature and proprietary environments. Traditional tools may fall short, making it difficult to track execution flows across services. However, modern solutions such as distributed tracing tools (e.g., AWS X-Ray, Datadog), centralized logging, and cloud-agnostic observability platforms are mitigating these challenges. Emerging technologies like OpenTelemetry, AI-powered anomaly detection, and serverless-specific frameworks are further improving visibility and root cause analysis. While challenges persist, advancements in monitoring and debugging tools are steadily addressing these limitations.\\n\\n\\n=== Security ===\\nAccording to OWASP, serverless applications are vulnerable to variations of traditional  attacks, insecure code, and some serverless-specific attacks (like Denial of Wallet). So, the risks have changed and attack prevention requires a shift in mindset.\\n\\n\\n=== Vendor lock-in ===\\nServerless computing is provided as a third-party service. Applications and software that run in the serverless environment are by default locked to a specific cloud vendor. This issue is exacerbated in serverless computing, as with its increased level of abstraction, public vendors only allow customers to upload code to a FaaS platform without the authority to configure underlying environments. More importantly, when considering a more complex workflow that includes Backend-as-a-Service (BaaS), a BaaS offering can typically only natively trigger a FaaS offering from the same provider. This makes the workload migration in serverless computing virtually impossible. Therefore, considering how to design and deploy serverless workflows from a multi-cloud perspective could mitigate th'), Document(metadata={'title': 'Elastic cloud storage', 'summary': \"An elastic cloud is a cloud computing offering that provides variable service levels based on changing needs.\\nElasticity is an attribute that can be applied to most cloud services. It states that the capacity and performance of any given cloud service can expand or contract according to a customer's requirements and that this can potentially be changed automatically as a consequence of some software-driven event or, at worst, can be reconfigured quickly by the customer's infrastructure management team.\\nElasticity has been described as one of the five main principles of cloud computing by Rosenburg and Mateos in The Cloud at Your Service - Manning 2011.\", 'source': 'https://en.wikipedia.org/wiki/Elastic_cloud_storage'}, page_content=\"An elastic cloud is a cloud computing offering that provides variable service levels based on changing needs.\\nElasticity is an attribute that can be applied to most cloud services. It states that the capacity and performance of any given cloud service can expand or contract according to a customer's requirements and that this can potentially be changed automatically as a consequence of some software-driven event or, at worst, can be reconfigured quickly by the customer's infrastructure management team.\\nElasticity has been described as one of the five main principles of cloud computing by Rosenburg and Mateos in The Cloud at Your Service - Manning 2011.\\n\\n\\n== History ==\\nCloud computing was first described by Gillet and Kapor in\\n1996;\\nhowever, the first practical implementation was a consequence of a strategy to leverage Amazon's excess data center capacity.\\nAmazon and other pioneers of the commercial use of this technology were primarily\\ninterested in providing a â€œpublicâ€ cloud service, whereby they could offer customers the benefits of using the cloud, particularly the utility-based\\npricing model benefit.\\nOther suppliers followed suit with a range of cloud-based\\nmodels all offering elasticity as a core component, but these suppliers were\\nonly offering this service as an element of their public cloud service.\\nDue to perceived weaknesses in security, or at least a lack\\nof proven compliance, many organizations, particularly in the financial and\\npublic sectors, have been slow adopters of cloud technologies. These\\nwary organizations can achieve some of the benefits of cloud computing by\\nadopting private\\ncloud\\ntechnologies.\\nAn alternative form of the elastic cloud has been offered\\nby vendors such as EMC  and\\nIBM,\\nwhereby the service is based around an enterprise's own infrastructure but\\nstill retains elements of elasticity and the potential to bill by consumption.\\n\\n\\n== Description ==\\nElasticity in cloud computing is the ability for the\\norganization to adjust its storage requirements in terms of capacity and\\nprocessing with respect to operational requirements. This has the following\\nbenefits:\\nOperational Benefits - Services\\ncan be acquired quickly, meaning that the evolving requirements of the business\\ncan be addressed almost immediately, giving an organization a potential agility\\nadvantage. A properly implemented elastic system will provision/de-provision\\naccording to application demands, so if a particular business has activity\\nspikes then the provision can be enabled to match the demand and the capacity\\ncan be re-allocated.\\nResearch and Development (R&D) Projects - R&D activities are no\\nlonger hindered by a requirement to secure a capex budget prior to a project\\nstarting. Capability can simply be provisioned from the cloud and released at\\nthe end of the exercise.\\nTesting and Deployment - With\\nmost large-scale projects a size test needs to be performed prior to final\\nrollout. By taking advantage of the elasticity of the cloud and creating a full-scale\\navatar of the proposed production system, realistic data and traffic volumes\\ncan be provisioned and released as needed.  \\nExpensive Resources Allocated - This will normally apply only\\nin the context where a customer is applying at least some of their own servers\\nas part of a cloud infrastructure, specifically where a business (for\\nperformance reasons) has decided to invest in solid-state storage as opposed to\\nspinning platters. There are instances when, due to activity spikes, a less\\ncritical process may need to be moved from the high-performance resources to\\nmore traditional storage.\\nServer Specification - When\\na customer has elected to own/lease hardware, they can select and specify\\nservers that are specifically tuned to meet the likely needs of their operation\\n(i.e., directly controlling the cost/benefit equation).\\nUtility Based Payments - There\\nis, of course, a key cost driver in this process, and the notion that you\\nshould pay for what you consume is acceptable for many organizati\"), Document(metadata={'title': 'Cloud computing security', 'summary': 'Cloud computing security or cloud security refers to a broad set of policies, technologies, applications, and controls used to protect virtualized IP, data, applications, services, and the associated infrastructure of cloud computing. It is a sub-domain of computer security, network security and, more broadly, information security.', 'source': 'https://en.wikipedia.org/wiki/Cloud_computing_security'}, page_content='Cloud computing security or cloud security refers to a broad set of policies, technologies, applications, and controls used to protect virtualized IP, data, applications, services, and the associated infrastructure of cloud computing. It is a sub-domain of computer security, network security and, more broadly, information security.\\n\\n\\n== Security issues associated with the cloud ==\\nCloud computing and storage provide users with the capability to store and process their data in third-party data centers. Organizations use the cloud in a variety of service models (e.g., SaaS, PaaS, IaaS) and deployment models (private, public, hybrid, and community).\\nSecurity concerns associated with cloud computing are typically divided into issues faced by cloud providers and those faced by their customers. The responsibility is shared and is often described in a vendorâ€™s \"shared responsibility model\". The provider must secure its infrastructure, while customers must secure their applications, identities, and configuration settings.\\nAnalyses of large-scale cloud incidents indicate that many breaches result from misconfigurations and long-unremediated exposures rather than solely from zero-day vulnerabilities.\\nWhen an organization stores data or hosts applications on the public cloud, it loses physical access to the hardware. As a result, potentially sensitive data may be at risk from insider attacks. According to a 2010 Cloud Security Alliance report, insider attacks rank among the top threats in cloud computing. Cloud service providers must ensure that thorough background checks are conducted for employees with physical access to data centers.\\nTo conserve resources and reduce cost, cloud providers often store multiple customersâ€™ data on the same server. As a result, one userâ€™s private data might be viewable by another without proper isolation. Providers implement data isolation and logical segregation to mitigate these risks.\\nThe extensive use of virtualization in cloud infrastructure brings unique security concerns. Virtualization introduces an additional layerâ€”the hypervisorâ€”that must be secured and correctly configured. A compromise of the hypervisor management system can impact an entire data center.\\n\\n\\n== Cloud security controls ==\\nCloud security architecture is effective only if the correct defensive implementations are in place. An efficient cloud security architecture should recognize the issues that will arise with security management and follow all the best practices, procedures, and guidelines to ensure a secure cloud environment. Security management addresses these issues with security controls. These controls protect cloud environments and are put in place to safeguard any weaknesses in the system and reduce the effect of an attack.\\n\\nDeterrent controls\\nAdministrative mechanisms intended to reduce attacks by informing attackers of consequences.\\nPreventive controls\\nControls designed to reduce vulnerabilities and prevent unauthorized access.\\nDetective controls\\nControls that detect and respond to security events. Includes monitoring, SIEM, IDS/IPS, malware detection.\\nCorrective controls\\nControls that reduce the impact of an incident and restore systems.\\n\\n\\n== Dimensions of cloud security ==\\nCloud security engineering is characterized by the security layers, plan, design, programming, and best practices that exist inside a cloud security arrangement. Cloud security engineering requires the composed and visual model (design and UI) to be characterized by the tasks inside the Cloud. This cloud security engineering process includes such things as access to the executives, techniques, and controls to ensure applications and information. It also includes ways to deal with and keep up with permeability, consistency, danger stance, and by and large security. Processes for imparting security standards into cloud administrations and activities assume an approach that fulfills consistent guidelines and essential foundation security parts.\\nThough th'), Document(metadata={'title': 'Cloud Native Computing Foundation', 'summary': 'The Cloud Native Computing Foundation (CNCF) is a subsidiary of the Linux Foundation founded in 2015 to support cloud-native computing.', 'source': 'https://en.wikipedia.org/wiki/Cloud_Native_Computing_Foundation'}, page_content='The Cloud Native Computing Foundation (CNCF) is a subsidiary of the Linux Foundation founded in 2015 to support cloud-native computing.\\n\\n\\n== History ==\\nIt was announced alongside Kubernetes 1.0, an open source container cluster manager, which was contributed to the Linux Foundation by Google as a seed technology. Founding members include Google, CoreOS, Mesosphere, Red Hat, Twitter, Huawei, Intel, RX-M, Cisco, IBM, Docker, Univa, and VMware. Today, CNCF is supported by over 450 members.\\nIn August 2018 Google announced that it was handing over operational control of Kubernetes to the community.\\n\\n\\n== Projects ==\\nArgo is a collection of tools for getting work done with Kubernetes. Among its main features are Workflows and Events. It was accepted to CNCF on March 26, 2020 at the Incubating maturity level and then moved to the Graduated maturity level on December 6, 2022.\\nCilium provides networking, security, and observability for Kubernetes deployments using eBPF technology. It joined the CNCF at incubation level in October 2021 and the CNCF announced its graduation in October 2023.\\ncontainerd is an industry-standard core container runtime. It is currently available as a daemon for Linux and Windows, which can manage the complete container lifecycle of its host system. In 2015, Docker donated the OCI Specification to The Linux Foundation with a reference implementation called runc. Since February 28, 2019 it is an official CNCF project. Its general availability and intention to donate the project to CNCF was announced by Docker in 2017.\\nCoreDNS is a DNS server that chains plugins. Its graduation was announced in 2019.\\nDapr, the distributed application runtime, provides APIs for building secure and reliable microservices and agentic AI systems. Dapr was donated to the CNCF in November 2021 and joined at incubation level. The CNCF announced its graduation in November 2024.\\nEnvoy: Originally built at Lyft to move their architecture away from a monolith, Envoy is a high-performance open source edge and service proxy that makes the network transparent to applications. Lyft contributed Envoy to Cloud Native Computing Foundation in September 2017.\\netcd is a distributed key value store, providing a method of storing data across a cluster of machines. It became a CNCF incubating project in 2018 at KubeCon+CloudNativeCon North America in Seattle that year.\\nFalco is an open source and cloud native runtime security initiative. It is the \"de facto Kubernetes threat detection engine\". It became an incubating project in January 2020  and graduated in February 2024.\\nFlux is an open source project for powering GitOps in Kubernetes clusters. It provides the GitOps Toolkit, a set of Kubernetes APIs that allow you to define how configuration source code is securely pulled into your cluster and deployed by popular Kubernetes manifests rendering engines like Kustomize and Helm. The most recommended source mechanism is the OCIRepository API, which provides enhanced security and benefits from container image tooling out there. Flux has also notification integrations with popular services like Prometheus Alertmanager, PagerDuty, Slack and so on. Flux has graduated in CNCF in 2022.\\nHarbor is an \"open source trusted cloud native registry project that stores, signs, and scans content.\" It became an incubating project in September 2019 and graduated in June 2020.\\nHelm is a package manager that helps developers \"easily manage and deploy applications onto the Kubernetes cluster.\" It joined the incubating level in June 2018 and graduated in April 2020.\\nIstio is a service mesh technology. It was accepted by CNCF in September 2022 and graduated on July 12, 2023.\\nJaeger, Created by Uber Engineering, Jaeger is an open source distributed tracing system inspired by Google Dapper paper and OpenZipkin community. It can be used for tracing microservice-based architectures, including distributed context propagation, distributed transaction monitoring, root cause analysis,'), Document(metadata={'title': 'Amazon (company)', 'summary': 'Amazon.com, Inc., doing business as Amazon, is an American multinational technology company engaged in e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. Founded in 1994 by Jeff Bezos in Bellevue, Washington, the company originally started as an online marketplace for books, but gradually expanded its offerings to include a wide range of product categories, referred to as \"The Everything Store\". Amazon has been described as a Big Tech company.\\nThe company has multiple subsidiaries, including Amazon Web Services, providing cloud computing; Zoox, a self-driving car division; Kuiper Systems, a satellite Internet provider; and Amazon Lab126, a computer hardware R&D provider. Other subsidiaries include Ring, Twitch, IMDb, and Whole Foods Market. Its acquisition of Whole Foods in August 2017 for US$13.4 billion substantially increased its market share and presence as a physical retailer. Amazon also distributes a variety of downloadable and streaming content through its Amazon Prime Video, MGM+, Amazon Music, Twitch, Audible and Wondery units. It publishes books through its publishing arm, Amazon Publishing, produces and distributes film and television content through Amazon MGM Studios, including the Metro-Goldwyn-Mayer studio it acquired in March 2022, and owns Brilliance Audio and Audible, which produce and distribute audiobooks, respectively. Amazon also produces consumer electronicsâ€”most notably, Kindle e-readers, Echo devices, Fire tablets, and Fire TVs.\\nAmazon has a reputation as a disruptor of industries through technological innovation and aggressive reinvestment of profits into capital expenditures. As of 2023, it is the world\\'s largest online retailer and marketplace, smart speaker provider, cloud computing service through AWS, live-streaming service through Twitch, and Internet company as measured by revenue and market share. In 2021, it surpassed Walmart as the world\\'s largest retailer outside of China, driven in large part by its paid subscription plan, Amazon Prime, which has 200 million subscribers worldwide. It is the second-largest private employer in the United States and the second-largest company in the world and in the U.S. by revenue as of 2024 (after Walmart). As of October 2024, Amazon is the 12th-most visited website in the world and 84% of its traffic comes from the United States. Amazon is also the global leader in research and development spending, with R&D expenditure of US$73 billion in 2022. Amazon has been criticized for its business practices, including surveillance partnerships, poor worker conditions, anti-union efforts, environmental harm, anti-competitive behavior, censorship controversies, and exploitative treatment of small businesses and suppliers.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Amazon_(company)'}, page_content='Amazon.com, Inc., doing business as Amazon, is an American multinational technology company engaged in e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. Founded in 1994 by Jeff Bezos in Bellevue, Washington, the company originally started as an online marketplace for books, but gradually expanded its offerings to include a wide range of product categories, referred to as \"The Everything Store\". Amazon has been described as a Big Tech company.\\nThe company has multiple subsidiaries, including Amazon Web Services, providing cloud computing; Zoox, a self-driving car division; Kuiper Systems, a satellite Internet provider; and Amazon Lab126, a computer hardware R&D provider. Other subsidiaries include Ring, Twitch, IMDb, and Whole Foods Market. Its acquisition of Whole Foods in August 2017 for US$13.4 billion substantially increased its market share and presence as a physical retailer. Amazon also distributes a variety of downloadable and streaming content through its Amazon Prime Video, MGM+, Amazon Music, Twitch, Audible and Wondery units. It publishes books through its publishing arm, Amazon Publishing, produces and distributes film and television content through Amazon MGM Studios, including the Metro-Goldwyn-Mayer studio it acquired in March 2022, and owns Brilliance Audio and Audible, which produce and distribute audiobooks, respectively. Amazon also produces consumer electronicsâ€”most notably, Kindle e-readers, Echo devices, Fire tablets, and Fire TVs.\\nAmazon has a reputation as a disruptor of industries through technological innovation and aggressive reinvestment of profits into capital expenditures. As of 2023, it is the world\\'s largest online retailer and marketplace, smart speaker provider, cloud computing service through AWS, live-streaming service through Twitch, and Internet company as measured by revenue and market share. In 2021, it surpassed Walmart as the world\\'s largest retailer outside of China, driven in large part by its paid subscription plan, Amazon Prime, which has 200 million subscribers worldwide. It is the second-largest private employer in the United States and the second-largest company in the world and in the U.S. by revenue as of 2024 (after Walmart). As of October 2024, Amazon is the 12th-most visited website in the world and 84% of its traffic comes from the United States. Amazon is also the global leader in research and development spending, with R&D expenditure of US$73 billion in 2022. Amazon has been criticized for its business practices, including surveillance partnerships, poor worker conditions, anti-union efforts, environmental harm, anti-competitive behavior, censorship controversies, and exploitative treatment of small businesses and suppliers.\\n\\n\\n== History ==\\n\\n\\n=== 1994â€“2009 ===\\n\\nAmazon was founded on July 5, 1994, by Jeff Bezos after he relocated from New York City to Bellevue, Washington, near Seattle, to operate an online bookstore. Bezos chose the Seattle area for its abundance of technical talent from Microsoft and the University of Washington, as well as its smaller population for sales tax purposes and the proximity to a major book distribution warehouse in Roseburg, Oregon. Bezos also considered several other options, including Portland, Oregon, and Boulder, Colorado. The company, originally named Cadabra, was founded in the converted garage of Bezos\\'s house for symbolic reasons and was renamed to Amazon in November 1994. The Amazon website launched for public sales on July 16, 1995, and initially sourced its books directly from wholesalers and publishers. Bezos retained the URL www.relentless.com, which he purchased when considering a name for the company; it redirects to the Amazon homepage.\\nAmazon went public in May 1997. It began selling music and videos in 1998, and began international operations by acquiring online sellers of books in the United Kingdom and Germany. In the subsequent year, it initiated the sale of a diverse rang'), Document(metadata={'title': 'Blueâ€“green deployment', 'summary': 'In software engineering, blueâ€“green deployment is a method of installing changes to a web, app, or database server by swapping alternating production and staging servers.', 'source': 'https://en.wikipedia.org/wiki/Blue%E2%80%93green_deployment'}, page_content='In software engineering, blueâ€“green deployment is a method of installing changes to a web, app, or database server by swapping alternating production and staging servers.\\n\\n\\n== Overview ==\\nIn blueâ€“green deployments, two servers are maintained: a \"blue\" server and a \"green\" server. At any given time, only one server is handling requests (e.g., being pointed to by the DNS). For example, public requests may be routed to the blue server, making it the production server and the green server the staging server, which can only be accessed on a private network. Changes are installed on the non-live server, which is then tested through the private network to verify the changes work as expected. Once verified, the non-live server is swapped with the live server, effectively making the deployed changes live.\\nUsing this method of software deployment offers the ability to quickly roll back to a previous state if anything goes wrong. This rollback is achieved by simply routing traffic back to the previous live server, which still does not have the deployed changes. An additional benefit to the blueâ€“green method of deployment is the reduced downtime for the server. Because requests are routed instantly from one server to the other, there is ideally no period where requests will be unfulfilled.\\nThe blueâ€“green deployment technique is often contrasted with the canary release deployment technique and it has similarities with  A/B testing.\\n\\n\\n== History ==\\nDan North and Jez Humble encountered differences between their test environments and the production environment while running Oracle WebLogic Server for a client sometime around 2005. To ensure safe deployment, they introduced a method where the new application version was deployed alongside the live system. This approach allowed for thorough testing and easy rollback in case of issues. The team initially considered naming these environments A and B but decided against it to avoid the perception that one was primary and the other secondary. They instead chose color-based names like blue, green, orange, and yellow, eventually using only blue and green since \"having two was sufficient\". This naming convention was adopted while working on the original Continuous delivery book published in 2010  and became a common term in the industry afterwards.\\n\\n\\n== Benefits and challenges ==\\nBlueâ€“green deployment is widely recognized for its ability to reduce downtime during application updates and minimize the risk of introducing defects into production environments. By maintaining two separate environmentsâ€”blue (the current live environment) and green (the environment with the updated version)â€”traffic can easily be switched between the two, ensuring that updates are rolled out without disrupting users. This method enables quick rollback in case of deployment failure, thus improving overall system resilience and user experience.\\nWhile blueâ€“green deployment reduces risks during updates, it also requires additional resources since two environments need to be maintained simultaneously. The cost of running duplicate infrastructure, even temporarily, can be prohibitive for smaller organizations. Furthermore, complex database migrations may pose challenges, as the system must ensure that both the blue and green environments have consistent data. Solutions to these issues often involve using database migration tools that allow for backward compatibility between environments.\\n\\n\\n== Implementation ==\\nThere are several approaches to implementing blueâ€“green deployments, each offering varying levels of automation and ease of use depending on the platform and tools available.\\n\\n\\n=== AWS CodeDeploy ===\\nAWS CodeDeploy facilitates blueâ€“green deployments by automating the entire process across services such as Amazon EC2 and AWS Lambda. The service shifts traffic between the old (blue) environment and the new (green) environment, minimizing downtime and ensuring a smooth transition. AWS CodeDeploy also allows the use of lifecycle '), Document(metadata={'title': 'Multicloud', 'summary': 'Multicloud (also written as multi-cloud or multi cloud) is a term with varying interpretations, generally referring to a system using multiple cloud computing providers. According to ISO/IEC 22123-1: \"multi-cloud is a cloud deployment model in which a customer uses public cloud services provided by two or more cloud service providers\". Multi-cloud can involve various deployment models, including public, private, and hybrid clouds, and multiple service models, such as Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). Multicloud incorporates workload, data, traffic and workflow portability options, exhibiting differing implementation complexities.\\nWhen effectively implemented, multicloud solutions can enhance architectural resilience, reduce dependence on a single vendor, and improve flexibility by leveraging services from different providers. However, multicloud strategies also present challenges, including increased operational complexity, security risks, higher costs, and integration difficulties.\\nAccording to the 2024 State of the Cloud Report by Flexera, multi-cloud adoption has continued to rise in 2024. Enterprises increasingly silo applications into specific clouds and select best-fit services. Key use cases include data analysis in separate clouds and cross-cloud disaster recovery.', 'source': 'https://en.wikipedia.org/wiki/Multicloud'}, page_content='Multicloud (also written as multi-cloud or multi cloud) is a term with varying interpretations, generally referring to a system using multiple cloud computing providers. According to ISO/IEC 22123-1: \"multi-cloud is a cloud deployment model in which a customer uses public cloud services provided by two or more cloud service providers\". Multi-cloud can involve various deployment models, including public, private, and hybrid clouds, and multiple service models, such as Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). Multicloud incorporates workload, data, traffic and workflow portability options, exhibiting differing implementation complexities.\\nWhen effectively implemented, multicloud solutions can enhance architectural resilience, reduce dependence on a single vendor, and improve flexibility by leveraging services from different providers. However, multicloud strategies also present challenges, including increased operational complexity, security risks, higher costs, and integration difficulties.\\nAccording to the 2024 State of the Cloud Report by Flexera, multi-cloud adoption has continued to rise in 2024. Enterprises increasingly silo applications into specific clouds and select best-fit services. Key use cases include data analysis in separate clouds and cross-cloud disaster recovery.\\n\\n\\n== Advantages and challenges ==\\nThere are several advantages to using a multicloud approach, including the ability to negotiate better pricing with cloud providers, the ability to quickly switch to another provider if needed, and the ability to avoid vendor lock-in. Multicloud can also be a good way to hedge against the risks of obsolescence, as it allows you to rely on multiple vendors and open standards, which can prolong the life of your systems.\\nAdditional benefits of the multicloud architecture include adherence to local policies that require certain data to be physically present within the area/country, geographical distribution of processing requests from physically closer cloud unit which in turn reduces latency and protect against disasters.\\nVarious issues and challenges also present themselves in a multicloud environment. Security and governance is more complicated, and more \"moving parts\" may create resiliency issues.\\n\\n\\n== Difference between multicloud and hybrid cloud ==\\nMulticloud differs from hybrid cloud in that it refers to multiple cloud services from different vendors rather than multiple deployment modes (on-premises hardware, and public and private, cloud hosting). However, when considering a broad definition of multi-cloud, hybrid cloud can still be regarded as a special form of multi-cloud.\\n\\n\\n== See also ==\\nCloud computing\\nServerless computing\\n\\n\\n== References =='), Document(metadata={'title': 'Carbyne (company)', 'summary': 'Carbyne Ltd. (formerly Reporty Homeland Security) is an Israeli technology company that develops advanced emergency communication technologies. Founded in 2015, Carbyne focuses on providing real-time video, location, and data transmission to enhance emergency response systems worldwide. Its platform enables public safety answering points (PSAPs) to receive critical information from callers, improving response times and situational awareness. The company, headquartered in New York with R&D operations in Tel Aviv, has attracted significant investments and partnered with global telecoms.\\nCarbyneâ€™s technology has been adopted by emergency services in 23 U.S. states and several other countries, including deployments in cities such as Miami, Atlanta, New Orleans, New York City and by agencies in Mexico and Colombia. In Israel, its platform has been used by the Tel Aviv and Jerusalem municipalities and the volunteer emergency organization United Hatzalah.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Carbyne_(company)'}, page_content=\"Carbyne Ltd. (formerly Reporty Homeland Security) is an Israeli technology company that develops advanced emergency communication technologies. Founded in 2015, Carbyne focuses on providing real-time video, location, and data transmission to enhance emergency response systems worldwide. Its platform enables public safety answering points (PSAPs) to receive critical information from callers, improving response times and situational awareness. The company, headquartered in New York with R&D operations in Tel Aviv, has attracted significant investments and partnered with global telecoms.\\nCarbyneâ€™s technology has been adopted by emergency services in 23 U.S. states and several other countries, including deployments in cities such as Miami, Atlanta, New Orleans, New York City and by agencies in Mexico and Colombia. In Israel, its platform has been used by the Tel Aviv and Jerusalem municipalities and the volunteer emergency organization United Hatzalah.\\n\\n\\n== History ==\\nCarbyne was founded in April 2015 by Amir Elichai (who serves as CEO), along with Alex Dizengoff (CTO), Yony Yatsun, and Lital Leshem under the name Reporty Homeland Security. The startup initially developed a platform for live video streaming and geolocation data to assist emergency call centers.\\nThe company rebranded to Carbyne in early 2018 â€“ a name referencing an extremely strong allotrope of carbon. By 2018 Carbyne had raised about $24 million in venture funding (including backing from Founders Fund, the first Israeli startup in that fundâ€™s portfolio) and was valued near $100 million.\\nIn April 2019, the company began collaborating with Cisco, the network equipment giant, to incorporate their hardware into its systems. Two months later, Carbyne announced a partnership with Google to integrate Android phone location services into emergency command centers across Mexico.\\nCarbyne established its headquarters in New York City in October 2019 while maintaining R&D operations in Tel Aviv, and it expanded with offices in the United States, Mexico, Europe, India, and Ukraine.\\nIn 2025, it secured a $100 million funding round led by strategic partners like AT&T, and reported deployments in roughly 300 emergency response centers worldwide.\\nIn November 2025, Axon Enterprise agreed to acquire Carbyne for $625 million in cash, intending to integrate Carbyne's AI-powered 911 technology into Axon's public safety ecosystem to enhance connected response capabilities.\\n\\n\\n== Products ==\\nCarbyne develops cloud-based â€œNext Generation 911â€ (NG911) solutions aimed at modernizing emergency communication. Its platform enables real-time transmission of rich data from callers to public safety answering points (PSAPs). For example, when a distress call is made, Carbyneâ€™s system can provide the 911 dispatcher with the callerâ€™s precise GPS location, live video feed from the callerâ€™s smartphone camera, audio streaming, text messaging, and other telemetry in parallel with the voice call. The company offers both an app-based service and an app-free option. With the Carbyne mobile app (previously called â€œC-Nowâ€), users can pre-install it on iOS or Android to automatically send video and location data during an emergency call.\\nAlternatively, Carbyneâ€™s web-based feature (known as â€œC-Liteâ€) allows a 911 center to text an auto-generated URL link to a caller, which when tapped activates the phoneâ€™s camera and streams video and location to the dispatcher â€“ all without requiring the caller to have any app installed. Both methods are cloud-native and work with legacy 911 infrastructure by creating an over-the-top data channel, enabling quick deployment with minimal changes to existing call centers. Carbyne claims its technology can significantly improve response efficiency (reducing emergency response times by up to 65% on average) by providing first responders with critical situational information before they arrive on scene. The platform also includes capabilities for indoor positioning (to locate caller\"), Document(metadata={'title': 'Google App Engine', 'summary': 'Google App Engine (also referred to as GAE or App Engine) is a cloud computing platform used as a service for developing and hosting web applications. Applications are sandboxed and run across multiple Google-managed servers. GAE supports automatic scaling for web applications, allocating more resources to the web application as the amount of requests increases. It was released as a preview in April 2008 and launched officially in September 2011.\\nApplications written in Go, PHP, Java, Python, Node.js, .NET, and Ruby are supported by the App Engine, and other languages can be supported at an additional cost. The free version of the service offers a standard environment with limited resources. Fees are charged for additional storage, bandwidth, or instance hours.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Google_App_Engine'}, page_content='Google App Engine (also referred to as GAE or App Engine) is a cloud computing platform used as a service for developing and hosting web applications. Applications are sandboxed and run across multiple Google-managed servers. GAE supports automatic scaling for web applications, allocating more resources to the web application as the amount of requests increases. It was released as a preview in April 2008 and launched officially in September 2011.\\nApplications written in Go, PHP, Java, Python, Node.js, .NET, and Ruby are supported by the App Engine, and other languages can be supported at an additional cost. The free version of the service offers a standard environment with limited resources. Fees are charged for additional storage, bandwidth, or instance hours.\\n\\n\\n== Features ==\\nGoogle App Engine primarily supports Go, PHP, Java, Python, Node.js, .NET, and Ruby applications, although it can also support other languages via \"custom runtimes\".\\nPython web frameworks that run on Google App Engine include Django, CherryPy, Pyramid, Flask, and web2py as well as a Google-written web app framework and several others designed specifically for the platform that was created after the release. Any Python framework that supports the WSGI using the CGI adapter can be used to create an application, and the framework can be uploaded with the developed application. Third-party libraries written in Python may also be uploaded.\\nSDK version 1.2.2 added support for bulk downloads of data using Python.\\nApp Engine\\'s integrated Google Cloud Datastore database has a SQL-like syntax called \"GQL\" (Google Query Language). GQL does not support the join statement. Instead, one-to-many and many-to-many relationships can be accomplished using ReferenceProperty().\\nGoogle Cloud Firestore is the successor to Google Cloud Datastore and replaces GQL with a document-based query method that treats stored objects as collections of documents. Firestore was launched in October 2017.\\n\\n\\n=== Backends ===\\nIn Google I/O 2011, Google announced App Engine Backends, which were allowed to run continuously and consume more memory. The Backend API was deprecated as of March 13, 2014, in favor of the Modules API. The Modules API introduced finer control over scaling, versioning, and resource allocation, allowing developers to run different parts of an application with distinct performance settings.\\n\\n\\n=== Google Cloud SQL ===\\nIn October 2011, Google previewed a zero-maintenance SQL database, which supports JDBC and DB-API. This service allows creating, configuring, and using relational databases with App Engine applications. Google Cloud SQL supports MySQL 8.0, 5.7, and 5.6.\\n\\n\\n=== Restrictions ===\\nDevelopers have read-only access to the file system on App Engine. Applications can use only virtual file systems.\\nApp Engine can only execute code called from an HTTP request (scheduled background tasks allow for self-calling HTTP requests).\\nUsers may upload arbitrary Python modules, but only if they are pure Python. C and Pyrex modules are not supported.\\nJava applications may only use a subset (The JRE Class White List) of the classes from the JRE standard edition. This restriction does not exist with the App Engine Standard Java8 runtime.\\nA process started on the server to answer a request can\\'t last more than 60 seconds (with the 1.4.0 release, this restriction does not apply to background jobs anymore).\\nDoes not support sticky sessions (a.k.a. session affinity), only replicated sessions are supported including limitation of the amount of data being serialized and time for session serialization.\\n\\n\\n=== Application hosting ===\\nWhile other services let users install and configure nearly any *NIX compatible software, App Engine requires developers to use only its supported languages, APIs, and frameworks. Current APIs allow storing and retrieving data from the document-oriented Google Cloud Datastore database, making HTTP requests, sending e-mail, manipulating images, and caching. Google '), Document(metadata={'title': 'Cloud-Based Secure File Transfer', 'summary': 'Cloud-Based Secure File Transfer is a managed or hosted file transfer service that provides cloud storage that can be accessed via SSH File Transfer Protocol (SFTP). These services allow secure, reliable file transfers while offering the scalability, redundancy, and high availability of cloud infrastructure.', 'source': 'https://en.wikipedia.org/wiki/Cloud-Based_Secure_File_Transfer'}, page_content='Cloud-Based Secure File Transfer is a managed or hosted file transfer service that provides cloud storage that can be accessed via SSH File Transfer Protocol (SFTP). These services allow secure, reliable file transfers while offering the scalability, redundancy, and high availability of cloud infrastructure.\\n\\n\\n== Technical overview ==\\nThe evolution of file transfer protocols began with File Transfer Protocol (FTP) and SSH File Transfer Protocol (SFTP). SFTP offered enhanced security through the use of SSH (Secure Shell) encryption, which addressed many of the security concerns associated with traditional FTP.\\nOver time, as businesses increasingly adopted cloud infrastructure, the demand for services that integrate secure file transfer with cloud storage led to the rise of Cloud-Based Secure File Transfer services. These services combine the benefits of secure, encrypted file transfer with the scalability and flexibility of cloud-based storage systems.\\nTraditional on-premises SFTP typically involves setting up and managing physical or virtual servers to handle file transfers. In contrast, Cloud-Based Secure File Transfer utilizes managed cloud infrastructure, such as AWS EC2, Azure VMs, or Google Cloud, to automate scaling, ensure redundancy, and provide high availability. These cloud environments can be configured to automatically scale with demand, enabling businesses to handle large volumes of data transfers without the need for extensive physical hardware.\\n\\n\\n== Features ==\\nScalability and availability: Cloud-Based Secure File Transfer services are inherently scalable, with features like load balancing, multi-region deployments, and auto-scaling groups that adjust resources in response to traffic spikes. This ensures that the system can handle varying workloads and provides continuous availability, even during high-demand periods.\\nCost-effectiveness: By eliminating the need for physical infrastructure and reducing ongoing server maintenance costs, Cloud-Based Secure File Transfer services offer significant cost savings compared to traditional on-premises services. Cloud providers typically offer pay-as-you-go pricing models, where users only pay for the resources they use, further optimizing costs.\\nSecurity and compliance: Cloud-Based Secure File Transfer products offer strong security measures, including end-to-end encryption, key management, detailed logging, and auditing. These services are often compliant with industry regulations such as HIPAA (Health Insurance Portability and Accountability Act), GDPR (General Data Protection Regulation), and SOC 2 (System and Organization Controls), ensuring that data transfers meet necessary security and privacy standards.\\n\\n\\n== Cloud-Based Secure File Transfer providers ==\\n\\n\\n== Uses ==\\nCloud-Based Secure File Transfer is used across various industries to securely transfer sensitive data and integrate into business workflows. In healthcare, Cloud-Based Secure File Transfer is essential for securely transferring electronic Protected Health Information (ePHI), ensuring compliance with regulations like HIPAA. In financial institutions, it is used to protect sensitive financial data during transfer, maintaining privacy and security. Data analytics also benefits from Cloud-Based Secure File Transfer, offering a secure and efficient method for transferring large datasets between systems or partners.\\nTechnically, Cloud-Based Secure File Transfer is often integrated into enterprise workflows through automated file transfers, using scripting or APIs. It also plays a key role in cloud backup and disaster recovery, ensuring that files are securely transferred and stored in cloud environments, which supports business continuity.\\nHowever, businesses must address certain implementation challenges. Despite its secure design, Cloud-Based Secure File Transfer is not immune to risks such as misconfigured SSH keys, improper access control, or inadequate encryption.\\nRegular security audits and careful co'), Document(metadata={'title': 'Cilium (computing)', 'summary': 'Cilium is a cloud native technology for networking, observability, and security. It is based on the kernel technology eBPF, originally for better networking performance, and now leverages many additional features for different use cases. The core networking component has evolved from only providing a flat Layer 3 network for containers to including advanced networking features, like BGP and Service mesh, within a Kubernetes cluster, across multiple clusters, and connecting with the world outside Kubernetes. Hubble was created as the network observability component and Tetragon was later added for security observability and runtime enforcement. Cilium runs on Linux and is one of the first eBPF applications being ported to Microsoft Windows through the eBPF on Windows project.', 'source': 'https://en.wikipedia.org/wiki/Cilium_(computing)'}, page_content=\"Cilium is a cloud native technology for networking, observability, and security. It is based on the kernel technology eBPF, originally for better networking performance, and now leverages many additional features for different use cases. The core networking component has evolved from only providing a flat Layer 3 network for containers to including advanced networking features, like BGP and Service mesh, within a Kubernetes cluster, across multiple clusters, and connecting with the world outside Kubernetes. Hubble was created as the network observability component and Tetragon was later added for security observability and runtime enforcement. Cilium runs on Linux and is one of the first eBPF applications being ported to Microsoft Windows through the eBPF on Windows project.\\n\\n\\n== History ==\\nEvolution from Networking CNI (Container Network Interface)\\nCilium began as a networking CNI for container workloads. It was originally IPv6 only and supported multiple container orchestrators, like Kubernetes. The original vision for Cilium was to build an intent and identity-based high-performance container networking platform. As the cloud native ecosystem expanded, Cilium added new projects and features to address new problems in the space.\\nThe table below summarises some of the most significant milestones of this evolution:\\n\\nDecember 2015 - Initial commit to the Cilium project\\nMay 2016 - Network policy was added, expanding the scope beyond just networking\\nAugust 2016 - Cilium was initially announced during LinuxCon as a project providing fast IPv6 container networking with eBPF and XDP. Today, Cilium has been adopted by major cloud provider's Kubernetes offerings and is one of the most widely used CNIs.\\nAugust 2017 - ebpf-go was created as a library to read, modify, and load eBPF programs and attach them to various hooks.\\nApril 2018 - Cilium 1.0 is the first stable release\\nNovember 2019 - Hubble was launched to provide eBPF-based observability to network flows\\nAugust 2020 - Chosen by Google as the basis for their Kubernetes Dataplane v2\\nSeptember 2021 - AWS picks Cilium for Networking & Security on EKS Anywhere\\nOctober 2021 - Pwru was launched for tracing network packets in the Linux kernel with advanced filtering capabilities\\nOctober 2021 - Accepted into CNCF as an incubation level project\\nDecember 2021 - Cilium Service Mesh launched to help manage traffic between services\\nMay 2022 - Tetragon open sourced to cover security observability and runtime enforcement\\nOctober 2022 - Chosen as CNI for Azure\\nApril 2023 - Cilium Mesh launched to connect workloads and machines across cloud, on-prem, and edge\\nApril 2023 - First CiliumCon hosted as a part of KubeCon\\nOctober 2023 - Cilium becomes a CNCF Graduated project \\n\\n\\n=== CNCF ===\\nCilium was accepted into the Cloud Native Computing Foundation on October 13, 2021 as an incubation-level project. It applied to become a graduated project on October 27, 2022. It became a Graduated project one year later. Cilium is one of the fastest-moving projects in the CNCF ecosystem.\\n\\n\\n=== Adoption ===\\nCilium has been adopted by many large-scale production users, including over 100 that have stated it publicly, for example:\\n\\nDatadog uses Cilium as their CNI and kube-proxy replacement\\nAscend uses Cilium as their one CNI across multiple cloud providers\\nBell Canada uses Cilium and eBPF for telco networking\\nCosmonic uses Cilium for their Nomad-based PaaS\\nIKEA uses Cilium for their self-hosted bare-metal private cloud\\nS&P Global uses Cilium as its CNI\\nSky uses Cilium as their CNI and for network security\\nThe New York Times uses Cilium on EKS for multi-region multi-tenant shared clusters\\nTrip.com uses Cilium both on premise and in AWS\\nOpenAI uses Cilium as their CNI\\nPalantir uses Cilium as their CNI across all major cloud providers\\nTikTok uses Cilium as their CNI in their IPv6-only datacenters\\nCilium is the CNI for many cloud providers including Alibaba, APPUiO, Azure, AWS, DigitalOcean, Exoscale, Google Cloud, Hetzn\"), Document(metadata={'title': 'OASIS TOSCA', 'summary': 'Topology and Orchestration Specification for Cloud Applications (TOSCA) is an OASIS standard language to describe a topology of cloud based web services, their components, relationships, and the processes that manage them. The TOSCA standard includes specifications of a file archive format called CSAR.', 'source': 'https://en.wikipedia.org/wiki/OASIS_TOSCA'}, page_content='Topology and Orchestration Specification for Cloud Applications (TOSCA) is an OASIS standard language to describe a topology of cloud based web services, their components, relationships, and the processes that manage them. The TOSCA standard includes specifications of a file archive format called CSAR.\\n\\n\\n== History ==\\nOn 16 January 2014, OASIS TOSCA Technical Committee approved TOSCA 1.0 as a standard. Version 1.3 was approved on 26 February 2020  and work is ongoing to define version 2.0\\n\\n\\n== Specification ==\\nThe specification is fully described in the standard  and has been cited in academic papers such as \\n\\n\\n=== Related specifications ===\\nCommercialization of cloud computing offerings has required manageability of tenant applications, particularly on a large scale.  As such, vendors who offer their services to a wide market have written related standards that predate, or have been developed concurrently, with the OASIS TOSCA standard.\\n\\n\\n==== Amazon AWS CloudFormation template ====\\nThe AWS CloudFormation template is a JSON data standard to allow cloud application administrators to define a collection of related AWS resources.\\nCloudFormation is a proprietary format from AWS, that is not TOSCA based, and therefore does not bring the promise OASIS TOSCA is targeting.\\nCheck this grammar  compared to the OASIS TOSCA one \\n.\\n\\n\\n==== OpenStack Heat ====\\nThe OpenStack Foundation has also defined a similar standard for specifying resources and the orchestrations for managing infrastructure, and application lifecycles.  The heat-translator project was one of the first to adopt TOSCA for standardized templating.\\n\\n\\n== Related projects ==\\n\\n\\n=== Cloudify ===\\nCloudify allows organizations an effortless transition to public cloud and Cloud-Native architecture by enabling them to automate their existing infrastructure alongside cloud native and distributed edge resources. Cloudify also allows users to manage different orchestration and automation domains as part of one common CI/CD pipeline.\\nCloudify is an open source, multi-cloud orchestration platform featuring unique technology that packages infrastructure, networking, and existing automation tools into certified blueprints. It is an open-source cloud orchestration framework. which enables you to model applications and services and automate their entire life cycle.\\n\\n\\n=== Alien4Cloud ===\\nApplication LIfecycle ENabler for Cloud (Alien4Cloud) is an open-source TOSCA based designer and cloud application lifecycle management platform. It is integrated with Yorc for runtime orchestration though other orchestrators can be plugged to it.\\n\\n\\n=== Opera (xOpera orchestrator) ===\\nThe xOpera project provides a set of tools for orchestration and automation of the cloud applications. The xOpera includes Opera orchestrator (Python library), a lightweight, open-source and state-aware orchestrator based on Ansible and TOSCA Simple Profile in YAML v1.3. The project also includes a tool, called Template Library Publishing Service, for publishing TOSCA components and templates. In 2021 xOpera project was presented on the TOSCA TC implementation stories webinar.\\n\\n\\n=== Yorc ===\\nYstia Orchestrator (Yorc) is an open-source TOSCA orchestration engine. It aims to support the whole application lifecycle, from deployment, scaling, monitoring, self-healing, self-scaling to application upgrade, over hybrid infrastructures (IaaS, HPC schedulers, CaaS).\\n\\n\\n=== Ubicity ===\\nUbicity provides tooling and orchestrators based on TOSCA.\\n\\n\\n=== MiCADOscale ===\\nMiCADOscale is an open-source TOSCA-based cloud resource orchestration framework for applications using Docker.\\n\\n\\n=== Infrastructure Manager ===\\nInfrastructure Manager (IM)  is an open-source TOSCA-based orchestration framework based on YAML.\\n\\n\\n== Related research projects ==\\n\\n\\n=== CloudCycle ===\\nCloudCycle was funded by the German Federal Ministry for Economic Affairs and Energy and ran from November 2011 to October 2014.\\nIt covered an open source TOSCA modeler and an open sou'), Document(metadata={'title': 'Pegasystems', 'summary': 'Pegasystems Inc. (Pega) is a global software company based in Waltham, Massachusetts, in the United States, and founded in 1983. The company has been publicly traded since 1996 as PEGA (NASDAQ). Pega is a platform for workflow automation and generative AI-powered decision-making for businesses.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Pegasystems'}, page_content=\"Pegasystems Inc. (Pega) is a global software company based in Waltham, Massachusetts, in the United States, and founded in 1983. The company has been publicly traded since 1996 as PEGA (NASDAQ). Pega is a platform for workflow automation and generative AI-powered decision-making for businesses.\\n\\n\\n== History ==\\n\\n\\n=== Early history ===\\nAlan Trefler founded Pegasystems in 1983 at the age of 27 in Cambridge, Massachusetts. Prior to founding the company, in the early 1980s, Trefler had developed computer systems that could play chess. During the company's early years, it focused on providing case management, namely for companies such as American Express. The company went public in 1996 with initial and secondary public offerings,  and began trading on NASDAQ under the symbol PEGA.\\n\\n\\n=== 2010â€“2019 ===\\nIn March 2010, Pegasystems acquired the enterprise software company Chordiant for around $161.5 million. The acquisition expanded Pegasystems into online training, telecommunications, and healthcare, integrating Chordiantâ€™s CRM technology into its operations. Pega Cloud was introduced using Amazon Web Services in 2012, and in October 2013, Pegasystems acquired the mobile application developer (based in KrakÃ³w and Bangalore) Antenna Software for $27.7 million.\\nIn 2014, Pegasystems invested in network operations in North America and India to support its cloud services. In 2014, Pegasystems acquired MeshLabs, a Bangalore-based text mining startup, and Firefly, a co-browsing tool.\\nAs of February 2015, the company had active partnerships with IT outsourcing companies such as Hexaware, NIIT Incessant Technologies, Tata Consultancy Services, Infosys, Wipro, HCL Technologies, Accenture, and Cognizant. Between 2005 and 2015, Pegasystems had an average sales growth of 21% per year. The company Pegasystems acquired OpenSpan Inc., an Atlanta-based company specializing in robotic process automation and workforce analytics software.\\nIn February 2019, Pegasystems purchased Infruid Labs, a business analytics and data visualization software company. In May 2019, the company bought In The Chat, a digital messaging platform.\\n\\n\\n=== 2020â€“present ===\\nIn April 2020, during the COVID-19 pandemic, Pegasystems launched an application for financial institutions to manage emergency loan applications from small businesses seeking COVID-19 financial relief. Throughout 2020, Pegasystems helped several of its clients, including the Bavarian government and the Commonwealth Bank of Australia, develop apps to manage issues that arose because of COVID-19.\\nIn May 2020, Pegasystems sponsored a Dropkick Murphys benefit concert at Fenway Park, featuring a virtual appearance by Bruce Springsteen. The live-streamed event raised over $700,000 for COVID relief and supported Habitat for Humanity, Feeding America, and the Boston Resiliency Fund.\\nIn January 2021, the company announced it had acquired Qurious.io, which provides a cloud service that analyzes voice calls in real time to support customer service representatives.\\nIn 2021, Pegasystems moved its headquarters to Waltham, Massachusetts, became the official Ryder Cup supplier, and sponsored golfers Marc Leishman and Mel Reid, with Reid notably wearing the companyâ€™s Pride logo in competition.\\nIn May 2022, a jury verdict awarded Appian Corporation $2.036 billion in damages for trade secret misappropriation and a damages award of $1 for a violation of the Virginia Computer Crimes Act. The company will not be required to begin paying the judgment until all avenues of appeal have been exhausted. In February 2023, Pega filed an appeal asking the court to overturn the previous judgment and either rule in Pegaâ€™s favor or order a new trial.\\nIn 2022, Pegasystems acquired Everflow, a Brazilian process mining company to support their process mining and hyper automation goals.\\nIn 2024, Pega expanded its GenAI capabilities to integrate with Large Language Models (LLMs) from Amazon Web Services (AWS) and Google Cloud.\\n\\n\\n== Products and ser\"), Document(metadata={'title': 'MongoDB Inc.', 'summary': 'MongoDB, Inc. is an American software company that develops and provides commercial support for the source-available database engine MongoDB, a database for unstructured data. Over the years, the company has expanded the product from its NoSQL roots to have broader appeal to enterprise customers, such as adding ACID and transactions.\\nIn 2016, the company introduced a SaaS version of the product, called Atlas. As of 2025 there were 59,000 MongoDB customers.\\nIn 2018, the company abandoned AGPL licensing of its product and in its stead introduced the Server Side Public License, which is not OSI-approved.\\nMongoDB, Inc. is a member of the MACH Alliance.', 'source': 'https://en.wikipedia.org/wiki/MongoDB_Inc.'}, page_content=\"MongoDB, Inc. is an American software company that develops and provides commercial support for the source-available database engine MongoDB, a database for unstructured data. Over the years, the company has expanded the product from its NoSQL roots to have broader appeal to enterprise customers, such as adding ACID and transactions.\\nIn 2016, the company introduced a SaaS version of the product, called Atlas. As of 2025 there were 59,000 MongoDB customers.\\nIn 2018, the company abandoned AGPL licensing of its product and in its stead introduced the Server Side Public License, which is not OSI-approved.\\nMongoDB, Inc. is a member of the MACH Alliance.\\n\\n\\n== History ==\\nThe company was first established in 2007 as 10gen. Based in New York City, 10gen was founded by former DoubleClick founder and CTO Dwight Merriman and former DoubleClick CEO and Gilt Groupe founder Kevin P. Ryan with former DoubleClick engineer and ShopWiki founder and CTO Eliot Horowitz and received $81 million in venture capital funding from Flybridge Capital Partners, In-Q-Tel, Intel Capital, New Enterprise Associates (NEA), Red Hat, Sequoia Capital, and Union Square Ventures. 10gen originally aimed to build a platform as a service architecture based entirely on open source components; however, the company was unable to find an existing database platform that met their principles for a cloud architecture. As a result, the company began to develop a document-oriented database system it called MongoDB. After realizing the potential of the software on its own, 10gen's team decided to scrap its cloud platform and focus on maintaining MongoDB instead. In February 2009, 10gen released MongoDB as an open source project. 10gen opened its first west coast office in August 2010, having offices in Palo Alto, Reston, London, Dublin, Barcelona, and Sydney by 2012.\\nIn September 2012, 10gen was in The Wall Street Journal's The Next Big Thing 2012.\\nOn August 27, 2013, 10gen announced that it would change its name to MongoDB Inc., associating itself more closely with what became its flagship products.\\nIn 2013, the Identification Authority of India adopted MongoDB's software to analyze registration trends for new identity documents used to obtain government benefits in India. This raised concerns of potential espionage, since at-the-time MongoDB was partially funded by the United States CIA venture capital arm, In-Q-Tel. As of 2013, there is no evidence in the public domain the CIA actually has any influence over MongoDB.\\nOn August 5, 2014, Dev Ittycheria was appointed president and chief executive officer.\\nBy 2017, MongoDB had raised $311 million in funding from venture capitalists. MongoDB filed for an initial public offering on September 21, 2017 and went public on NASDAQ that October 20. It raised $192 million, valuing the company at $1.6 billion overall. Its market capitalization varied greatly afterwards, reaching $39 billion in 2021 and coming back down to $10 billion by 2024.\\nMongoDB acquired database engine company WiredTiger in 2014, followed by database-as-a-service company MLab for $68 million in 2018. The following year, in 2019, MongoDB acquired a mobile-focused database company called Realm for $39 million.\\nA secondary public offering was held on June 29, 2021. In 2022, MongoDB established its own venture capital fund.\\nOn November 3, 2025, MongoDB announced that its Board of Directors has appointed Chirantan â€œCJâ€ Desai as President and Chief Executive Officer (â€œCEOâ€), effective November 10, 2025. \\n\\n\\n== Software ==\\nAs of 2025, MongoDB was the fifth most popular database software. It focuses mostly on managing large databases of unstructured data. It's typically used for mobile and web apps that commonly use unstructured databases. As of 2024, there were 50,000 MongoDB customers. MongoDB was originally best known as a NoSQL database product. The company released a database as-a-service product called Atlas in 2016 that became 70 percent of MongoDB's revenue by 2024. O\"), Document(metadata={'title': 'Multi-access edge computing', 'summary': 'Multi-access edge computing (MEC), formerly mobile edge computing, is an ETSI-defined network architecture concept that enables cloud computing capabilities and an IT service environment at the edge of the cellular network and, more in general at the edge of any network. The basic idea behind MEC is that by running applications and performing related processing tasks closer to the cellular customer, network congestion is reduced and applications perform better. MEC technology is designed to be implemented at the cellular base stations or other edge nodes, and enables flexible and rapid deployment of new applications and services for customers. Combining elements of information technology and telecommunications networking, MEC also allows cellular operators to open their radio access network (RAN) to authorized third parties, such as application developers and content providers.\\nTechnical standards for MEC are being developed by the European Telecommunications Standards Institute, which has produced a technical white paper about the concept.', 'source': 'https://en.wikipedia.org/wiki/Multi-access_edge_computing'}, page_content='Multi-access edge computing (MEC), formerly mobile edge computing, is an ETSI-defined network architecture concept that enables cloud computing capabilities and an IT service environment at the edge of the cellular network and, more in general at the edge of any network. The basic idea behind MEC is that by running applications and performing related processing tasks closer to the cellular customer, network congestion is reduced and applications perform better. MEC technology is designed to be implemented at the cellular base stations or other edge nodes, and enables flexible and rapid deployment of new applications and services for customers. Combining elements of information technology and telecommunications networking, MEC also allows cellular operators to open their radio access network (RAN) to authorized third parties, such as application developers and content providers.\\nTechnical standards for MEC are being developed by the European Telecommunications Standards Institute, which has produced a technical white paper about the concept.\\n\\n\\n== Distributed computing in the RAN ==\\nMEC provides a distributed computing environment for application and service hosting. It also has the ability to store and process content close to cellular subscribers, for faster response time. Applications can also be exposed to real-time radio access network (RAN) information.\\nThe key element is the MEC application server, which is integrated at the RAN element. This server provides computing resources, storage capacity, connectivity and access to RAN information. It supports a multitenancy run-time and hosting environment for applications.  The virtual appliance applications are delivered as packaged operating system virtual machine (VM) images or containers incorporating operating systems and applications. The platform also provides a set of middleware application and infrastructure services. Application software can be provided from equipment vendors, service providers and third-parties.\\n\\n\\n== Deployment ==\\nThe MEC application server can be deployed at the macro base station EnodeB that is part of an LTE cellular network, or at the Radio Network Controller (RNC) that is part of a 3G cellular network and at a multi-technology cell aggregation site. The multi-technology cell aggregation site can be located indoors or outdoors.\\n\\n\\n== Business and technical benefits ==\\nBy using mobile edge computing technology, a cellular operator can efficiently deploy new services for specific customers or classes of customers. The technology also reduces the signal load of the core network, and can host applications and services in a less costly way. It also collects data about storage, network bandwidth, CPU utilization, etc., for each application or service deployed by a third party. Application developers and content providers can take advantage of close proximity to cellular subscribers and real-time RAN information.\\nMEC has been created using open standards and application programming interfaces (APIs), using common programming models, relevant tool chains and software development kits to encourage and expedite the development of new applications for the new MEC environment.\\n\\n\\n== Applications ==\\nSince MEC architecture has only recently been proposed, there are as yet very few applications that have adopted this architecture. However, many case studies have been proposed in recent articles. Some of the notable applications in mobile edge computing are computational offloading, content delivery, mobile big data analytics, edge video caching, collaborative computing, connected cars, smart venues, smart enterprises, healthcare, smartgrids, service function chaining, indoor positioning, etc.\\n\\n\\n== Current uses ==\\nSome applications which incorporate MEC were made available in 2015. For example, active device location tracking allows operators to track active terminal equipment, independent of Global Positioning System devices. This is based on third-party geolocati'), Document(metadata={'title': 'Continuous delivery', 'summary': 'Continuous delivery (CD) is a software engineering approach in which teams produce software in short cycles, ensuring that the software can be reliably released at any time. It aims at building, testing, and releasing software with greater speed and frequency. The approach helps reduce the cost, time, and risk of delivering changes by allowing for more incremental updates to applications in production. A straightforward and repeatable deployment process is important for continuous delivery.', 'source': 'https://en.wikipedia.org/wiki/Continuous_delivery'}, page_content='Continuous delivery (CD) is a software engineering approach in which teams produce software in short cycles, ensuring that the software can be reliably released at any time. It aims at building, testing, and releasing software with greater speed and frequency. The approach helps reduce the cost, time, and risk of delivering changes by allowing for more incremental updates to applications in production. A straightforward and repeatable deployment process is important for continuous delivery.\\n\\n\\n== Principles ==\\nAccording to Neal Ford, continuous delivery adopts \"Bring the pain forward,\" tackling tough tasks early, fostering automation and swift issue detection.\\nContinuous delivery treats the commonplace notion of a deployment pipeline as a lean Poka-Yoke: a set of validations through which a piece of software must pass on its way to release. Code is compiled if necessary and then packaged by a build server every time a change is committed to a source control repository, then tested by a number of different techniques (possibly including manual testing) before it can be marked as releasable.\\nDevelopers used to a long cycle time may need to change their mindset when working in a CD environment. Any code commit may be released to customers at any point. Patterns such as feature toggles can be very useful for committing code early which is not yet ready for use by end users. Using NoSQL can eliminate the step of data migrations and schema changes, often manual steps or exceptions to a continuous delivery workflow. Other useful techniques for developing code in isolation such as code branching are not obsolete in a CD world, but must be adapted to fit the principles of CD - for example, running multiple long-lived code branches can prove impractical, as a releasable artifact must be built early in the CD process from a single code branch if it is to pass through all phases of the pipeline.\\n\\n\\n== Deployment pipeline ==\\n\\nContinuous delivery is enabled through the deployment pipeline. The purpose of the deployment pipeline has three components: visibility, feedback, and continually deploy.\\n\\nVisibility â€“ All aspects of the delivery system including building, deploying, testing, and releasing are visible to every member of the team to promote collaboration.\\nFeedback â€“ Team members learn of problems as soon as possible when they occur so that they are able to fix them as quickly as possible.\\nContinually deploy â€“ Through a fully automated process, you can deploy and release any version of the software to any environment.\\n\\nAccording to Yan Cui, when it comes to serverless environments, ephemeral resources should be kept together and have their own deployment pipeline to achieve a high cohesion. However, shared resources that have a long spin-up time and landing zone should have their own separate repository, deployment pipeline and stack.\\n\\n\\n== Tools/tool types ==\\nContinuous delivery takes automation from source control all the way through production. There are various tools that help accomplish all or part of this process. These tools are part of the deployment pipeline which includes continuous delivery. The types of tools that execute various parts of the process include: continuous integration, application release automation, build automation, application lifecycle management.\\n\\n\\n== Architecting for continuous delivery ==\\nTo practice continuous delivery effectively, software applications have to meet a set of architecturally significant requirements (ASRs) such as deployability, modifiability, and testability. These ASRs require a high priority and cannot be traded off lightly.\\nMicroservices are often used when architecting for continuous delivery. The use of Microservices can increase a software system\\'s deployability and modifiability. The observed deployability improvements include: deployment independence, shorter deployment time, simpler deployment procedures, and zero downtime deployment. The observed modifiability improvements includ'), Document(metadata={'title': 'Network Device Interface', 'summary': 'Network Device Interface (NDI) is a software specification developed by the technology company NewTek. It enables high-definition video to be transmitted, received, and communicated over a computer network with low latency and high quality. This royalty-free specification supports frame-accurate switching, making it suitable for live video production environments.', 'source': 'https://en.wikipedia.org/wiki/Network_Device_Interface'}, page_content='Network Device Interface (NDI) is a software specification developed by the technology company NewTek. It enables high-definition video to be transmitted, received, and communicated over a computer network with low latency and high quality. This royalty-free specification supports frame-accurate switching, making it suitable for live video production environments.\\n\\n\\n== Technology ==\\nNDI is designed to run over gigabit Ethernet with the NDI codec. It delivers 1080i high-definition video at variable data rates typically around 100 Mbit/s.\\nBy default, NDI uses multicast DNS to advertise sources on a local area network, such that NDI receivers can automatically discover and offer those sources. It also supports two other discovery modes (NDI Access, NDI Discovery Server) that allow for operations across subnets and without multicast DNS. Sources are created using an arbitrarily selected TCP port from a range of ports on the NDI senders. When a source is requested, a TCP connection is established on the appropriate port with the NDI receiver connecting to the NDI sender. NDI 3.x has options to use UDP multicast or unicast with forward error correction (FEC) instead of TCP, and can load balance streams across multiple network interface controllers (NICs) without using link aggregation. NDI version 4.0 introduces the Multi-TCP transport.\\nNDI carries video, multichannel uncompressed audio, and metadata. Metadata messages can be sent in both directions allowing the sender and receiver to message one another over the connection with arbitrary metadata in XML form. This directional metadata system allows for functionality such as active tally information fed back to sources to understand that they are on-air. NDI also allows senders to determine the number of connected receivers, so they can skip unnecessary processing and network bandwidth utilisation when there are no NDI receiver clients connected. NDI Receivers can opt to connect to various combinations of streams, to support, for instance, audio-only or metadata-only connections where video is not required.\\nThe NDI software development kit (SDK) is available for Windows, Linux, and MacOS, and has also been ported to iOS, tvOS, Android, Raspberry Pi, and FPGA. The Standard NDI SDK is available via a royalty-free proprietary license. The NDI Advanced SDK offers OEMs direct access to and from compressed data and other features, with a commercial license.\\n\\n\\n== Comparison of common IP video protocols ==\\nOther IP video protocols for use in professional video production (rather than IP video used for distribution to end users) include SMPTE 2022, SMPTE 2110, ASPEN (largely superseded by SMPTE 2110) and Sony NMI. There are clear differences in the technology used by these protocols. \\n\\n\\n== History ==\\nNDI was publicly revealed by NewTek on 8 September 2015 and was demonstrated at the International Broadcasting Convention in Amsterdam that week.  The first device shown using NDI was the NewTek TriCaster which delivered an NDI feed from each of its SDI inputs as well as four output feeds from its vision mixer. The TriCaster could also receive up to two NDI sources from other devices.\\nNewTek had previously created a predecessor of NDI called AirSend to get video from external devices into their TriCaster products. AirSend had been implemented by a number of character generator (CG) vendors including Vizrt and Chyron. In order to quickly bring these products into the NDI space, NewTek created a new driver to replace the existing AirSend driver, which could be installed on these existing AirSend-compatible devices, instantly converting them to NDI-compatible devices with no change required by the original CG vendors.\\nBirdDog was an early adopter and in 2018 released Studio NDI, an ASIC implementation of NDI. BirdDog went on to deliver NDI PTZ cameras, along with a host of software applications.\\nAnother early adopter of NDI was VMix, a Windows-based vision mixer that offers NDI inputs and outputs. '), Document(metadata={'title': 'Continuous integration', 'summary': 'Continuous integration (CI) is the practice of integrating source code changes frequently and ensuring that the integrated codebase is in a workable state. Typically, developers merge changes to an integration branch, and an automated system builds and tests the software system. \\nOften, the automated process runs on each commit or runs on a schedule such as once a day. Grady Booch first proposed the term CI in 1991, although he did not advocate integrating multiple times a day, but later, CI came to include that aspect.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Continuous_integration'}, page_content='Continuous integration (CI) is the practice of integrating source code changes frequently and ensuring that the integrated codebase is in a workable state. Typically, developers merge changes to an integration branch, and an automated system builds and tests the software system. \\nOften, the automated process runs on each commit or runs on a schedule such as once a day. Grady Booch first proposed the term CI in 1991, although he did not advocate integrating multiple times a day, but later, CI came to include that aspect.\\n\\n\\n== History ==\\n\\nThe earliest known work (1989) on continuous integration was the Infuse environment developed by G. E. Kaiser, D. E. Perry, and W. M. Schell.\\nIn 1994, Grady Booch used the phrase continuous integration in Object-Oriented Analysis and Design with Applications (2nd edition) to explain how, when developing using micro processes, \"internal releases represent a sort of continuous integration of the system, and exist to force closure of the micro process\".\\nIn 1997, Kent Beck and Ron Jeffries invented extreme programming (XP) while on the Chrysler Comprehensive Compensation System project, including continuous integration. Beck published about continuous integration in 1998, emphasising the importance of face-to-face communication over technological support. In 1999, Beck elaborated more in his first full book on Extreme Programming. CruiseControl, one of the first open-source CI tools, was released in 2001.\\nIn 2010, Timothy Fitz published an article detailing how IMVU\\'s engineering team had built and been using the first practical CD system. While his post was originally met with skepticism, it quickly caught on and found widespread adoption as part of the lean software development methodology, also based on IMVU.\\n\\n\\n== Practices ==\\nThe core activities of CI are developers co-locate code changes in a shared, integration area frequently and that the resulting integrated codebase is verified for correctness. The first part generally involves merging changes to a common version control branch. The second part generally involves automated processes including: building, testing and many other processes.\\nTypically, a server builds from the integration area frequently; i.e. after each commit or periodically like once a day. The server may perform quality control checks such as running unit tests and collect software quality metrics via processes such as static analysis and performance testing.\\n\\n\\n=== Build automation ===\\n\\nBuild automation is a best practice. Build automation tools automate building. \\nProponents of CI recommend that a single command should have the capability of building the system. \\nAutomation often includes automating the integration, which often includes deployment into a production-like environment. In many cases, the build script not only compiles binaries but also generates documentation, website pages, statistics and distribution media (such as Debian DEB, Red Hat RPM or Windows MSI files).\\n\\n\\n=== Atomic commits ===\\nCI requires the version control system to support atomic commits; i.e., all of a developer\\'s changes are handled as a single commit.\\n\\n\\n=== Committing changes ===\\nWhen making a code change, a developer creates a branch that is a copy of the current codebase. As other changes are committed to the repository, this copy diverges from the latest version.\\nThe longer development continues on a branch without merging to the integration branch, the greater the risk of multiple integration conflicts and failures when the developer branch is eventually merged back. When developers submit code to the repository they must first update their code to reflect the changes in the repository since they took their copy. The more changes the repository contains, the more work developers must do before submitting their own changes.\\nEventually, the repository may become so different from the developers\\' baselines that they enter what is sometimes referred to as \"merge hell\", or \"integration hell\", '), Document(metadata={'title': 'Personalized marketing', 'summary': 'Personalized marketing, also known as one-to-one marketing or individual marketing, is a marketing strategy by which companies use data analysis and digital technology to show adverts to individuals based on their perceived characteristics and interests. Marketers use methods from data collection, analytics, digital electronics, and digital economics then use technology to analyze it and show personalized ads based on algorithms that attempt to deduce peopleâ€™s interests.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Personalized_marketing'}, page_content=\"Personalized marketing, also known as one-to-one marketing or individual marketing, is a marketing strategy by which companies use data analysis and digital technology to show adverts to individuals based on their perceived characteristics and interests. Marketers use methods from data collection, analytics, digital electronics, and digital economics then use technology to analyze it and show personalized ads based on algorithms that attempt to deduce peopleâ€™s interests.\\n\\n\\n== Technology ==\\nPersonalized marketing is dependent on many different types of technology for data collection, data classification, data analysis, data transfer, and data scalability. Technology enables marketing professionals to collect first-party data such as gender, age group, location, and income, as well as connect them with third-party data such as click-through rates of online banner ads and social media participation.\\nData Management Platforms: A data management platform (DMP) is a centralized computing system for collecting, integrating and managing large sets of structured and unstructured data from disparate sources. Personalized marketing enabled by DMPs, is sold to advertisers with the goal of having consumers receive relevant, timely, engaging, and personalized messaging and advertisements that resonate with their unique needs and wants. Growing number of DMP software options are available including Adobe Systems Audience Manager and Core Audience (Marketing Cloud) to Oracle-acquired BlueKai, Sitecore Experience Platform and X+1\\nCustomer Relationship Management Platforms: Customer relationship management (CRM) is used by companies to manage and analyze customer interactions and data throughout the customer lifecycle, improving relationships, boosting retention, and driving sales growth. CRM systems are designed to compile information on customers across different channels (points of contact between the customer and the company) which could include the company's website, live support, direct mail, marketing materials and social media. CRM systems can also give customer-facing staff detailed information on customers' personal information, purchase history, buying preferences and concerns. Most popular enterprise CRM applications are Salesforce.com, Microsoft Dynamics CRM, NetSuite, Hubspot, and Oracle Eloqua.\\nBeacon Technology: Beacon technology works on Bluetooth low energy (BLE) which is used by a low frequency chip that is found in devices like mobile phones. These chips communicate with multiple Beacon devices to form a network and are used by marketers to better personalize the messaging and mobile ads based on the customer's proximity to their retail outlet. Beacon technology circumference has shrunk, ultimately facilitating its use. \\n\\n\\n== Strategies ==\\nOne-to-one marketing refers to marketing strategies applied directly to a specific consumer. Having knowledge of the consumer's preferences, enables suggesting specific products and promotions to each consumer. One-to-one marketing is based on four main steps in order to fulfill its goals: identify, differentiate, interact, and customize.\\n\\nIdentify: The focus is on getting to know the customers of a company, to collect reliable data about their preferences and how their needs can best be satisfied. Knowing a consumer's behaviors and habits allows a company to properly target them.\\nDifferentiate: Involves distinguishing the customers in terms of their lifetime value to the company, knowing them by their priorities in terms of their needs, and segmenting them into more restricted groups. Ultimately, differentiating customers will help create a strategy targeted to those specific groups.\\nInteract: One needs to know by which communication channel and by what means, contact with the client is best made. It is necessary to get the customer's attention by engaging with him/her in ways that are known as being the ones that he/she enjoys the most. It is important to maintain an ongoing conversation\"), Document(metadata={'title': 'Confidential computing', 'summary': 'Confidential computing is a security and privacy-enhancing computational technique focused on protecting data in use. Confidential computing can be used in conjunction with storage and network encryption, which protect data at rest and data in transit respectively. It is designed to address software, protocol, cryptographic, and basic physical and supply-chain attacks, although some critics have demonstrated architectural and side-channel attacks effective against the technology.\\nThe technology protects data in use by performing computations in a hardware-based trusted execution environment (TEE). Confidential data is released to the TEE only once it is assessed to be trustworthy. Different types of confidential computing define the level of data isolation used, whether virtual machine, application, or function, and the technology can be deployed in on-premise data centers, edge locations, or the public cloud. It is often compared with other privacy-enhancing computational techniques such as fully homomorphic encryption, secure multi-party computation, and Trusted Computing.\\nConfidential computing is promoted by the Confidential Computing Consortium (CCC) industry group, whose membership includes major providers of the technology.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Confidential_computing'}, page_content='Confidential computing is a security and privacy-enhancing computational technique focused on protecting data in use. Confidential computing can be used in conjunction with storage and network encryption, which protect data at rest and data in transit respectively. It is designed to address software, protocol, cryptographic, and basic physical and supply-chain attacks, although some critics have demonstrated architectural and side-channel attacks effective against the technology.\\nThe technology protects data in use by performing computations in a hardware-based trusted execution environment (TEE). Confidential data is released to the TEE only once it is assessed to be trustworthy. Different types of confidential computing define the level of data isolation used, whether virtual machine, application, or function, and the technology can be deployed in on-premise data centers, edge locations, or the public cloud. It is often compared with other privacy-enhancing computational techniques such as fully homomorphic encryption, secure multi-party computation, and Trusted Computing.\\nConfidential computing is promoted by the Confidential Computing Consortium (CCC) industry group, whose membership includes major providers of the technology.\\n\\n\\n== Properties ==\\nTrusted execution environments (TEEs) \"prevent unauthorized access or modification of applications and data while they are in use, thereby increasing the security level of organizations that manage sensitive and regulated data\". Trusted execution environments can be instantiated on a computer\\'s processing components such as a central processing unit (CPU) or a graphics processing unit (GPU).  In their various implementations, TEEs can provide different levels of isolation including virtual machine, individual application, or compute functions.\\nTypically, data in use in a computer\\'s compute components and memory exists in a decrypted state and can be vulnerable to examination or tampering by unauthorized software or administrators. According to the CCC, confidential computing protects data in use through a minimum of three properties:\\n\\nData confidentiality: \"Unauthorized entities cannot view data while it is in use within the TEE\".\\nData integrity: \"Unauthorized entities cannot add, remove, or alter data while it is in use within the TEE\".\\nCode integrity: \"Unauthorized entities cannot add, remove, or alter code executing in the TEE\".\\nIn addition to trusted execution environments, remote cryptographic attestation is an essential part of confidential computing.  The attestation process assesses the trustworthiness of a system and helps ensure that confidential data is released to a TEE only after it presents verifiable evidence that it is genuine and operating with an acceptable security posture.  It allows the verifying party to assess the trustworthiness of a confidential computing environment through an \"authentic, accurate, and timely report about the software and data state\" of that environment. \"Hardware-based attestation schemes rely on a trusted hardware component and associated firmware to execute attestation routines in a secure environment\". Without attestation, a compromised system could deceive others into trusting it, claim it is running certain software in a TEE, and potentially compromise the confidentiality or integrity of the data being processed or the integrity of the trusted code.\\n\\n\\n== Technical approaches ==\\nTechnical approaches to confidential computing may vary in which software, infrastructure and administrator elements are allowed to access confidential data. The \"trust boundary,\" which circumscribes a trusted computing base (TCB), defines which elements have the potential to access confidential data, whether they are acting benignly or maliciously.  Confidential computing implementations enforce the defined trust boundary at a specific level of data isolation. The three main types of confidential computing are:\\n\\nVirtual machine isolation\\nApplication isolation'), Document(metadata={'title': 'OpenAI', 'summary': 'OpenAI is an American artificial intelligence (AI) organization headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\". As a leading organization in the ongoing AI boom, OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image models, and a text-to-video model named Sora. Its release of ChatGPT in November 2022 has been credited with catalyzing widespread interest in generative AI.\\nThe organization has a complex corporate structure. As of October 2025, it is led by the non-profit OpenAI Foundation, founded in 2015 and registered in Delaware, which holds a 26% equity stake in OpenAI Group PBC, a for-profit public benefit corporation which commercializes its products. Microsoft invested over $13 billion into OpenAI, and provides Azure cloud computing resources. In October 2025, OpenAI conducted a $6.6 billion share sale that valued the company at $500 billion. On 28 October 2025, OpenAI said it had converted its main business into a for-profit corporation, with Microsoft acquiring a 27% stake in the company and the remaining non-profit company (now known as the OpenAI Foundation) owning a 26% stake.\\nIn 2023 and 2024, OpenAI faced multiple lawsuits for alleged copyright infringement against authors and media companies whose work was used to train some of OpenAI\\'s products. In November 2023, OpenAI\\'s board removed Sam Altman as CEO, citing a lack of confidence in him, but reinstated him five days later following a reconstruction of the board. Throughout 2024, roughly half of then-employed AI safety researchers left OpenAI, citing the company\\'s prominent role in an industry-wide problem.', 'source': 'https://en.wikipedia.org/wiki/OpenAI'}, page_content='OpenAI is an American artificial intelligence (AI) organization headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\". As a leading organization in the ongoing AI boom, OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image models, and a text-to-video model named Sora. Its release of ChatGPT in November 2022 has been credited with catalyzing widespread interest in generative AI.\\nThe organization has a complex corporate structure. As of October 2025, it is led by the non-profit OpenAI Foundation, founded in 2015 and registered in Delaware, which holds a 26% equity stake in OpenAI Group PBC, a for-profit public benefit corporation which commercializes its products. Microsoft invested over $13 billion into OpenAI, and provides Azure cloud computing resources. In October 2025, OpenAI conducted a $6.6 billion share sale that valued the company at $500 billion. On 28 October 2025, OpenAI said it had converted its main business into a for-profit corporation, with Microsoft acquiring a 27% stake in the company and the remaining non-profit company (now known as the OpenAI Foundation) owning a 26% stake.\\nIn 2023 and 2024, OpenAI faced multiple lawsuits for alleged copyright infringement against authors and media companies whose work was used to train some of OpenAI\\'s products. In November 2023, OpenAI\\'s board removed Sam Altman as CEO, citing a lack of confidence in him, but reinstated him five days later following a reconstruction of the board. Throughout 2024, roughly half of then-employed AI safety researchers left OpenAI, citing the company\\'s prominent role in an industry-wide problem.\\n\\n\\n== Founding ==\\n\\nIn December 2015, OpenAI was founded as a not for profit organization by Sam Altman, Elon Musk, Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk as the co-chairs. A total of $1 billion in capital was pledged by Sam Altman, Greg Brockman, Elon Musk, Reid Hoffman, Jessica Livingston, Peter Thiel, Amazon Web Services (AWS), and Infosys. The actual collected total amount of contributions was only $130 million until 2019.\\nThe organization stated it would \"freely collaborate\" with other institutions and researchers by making some of its patents and research open to the public. OpenAI was initially run from Brockman\\'s living room. It was later headquartered at the Pioneer Building in the Mission District, San Francisco.\\nAccording to OpenAI\\'s charter, its founding mission is \"to ensure that artificial general intelligence (AGI)â€”by which we mean highly autonomous systems that outperform humans at most economically valuable workâ€”benefits all of humanity.\"\\nMusk and Altman stated in 2015 that they were partly motivated by concerns about AI safety and existential risk from artificial general intelligence. OpenAI stated that \"it\\'s hard to fathom how much human-level AI could benefit society\", and that it is equally difficult to comprehend \"how much it could damage society if built or used incorrectly\". The startup also wrote that AI \"should be an extension of individual human wills and, in the spirit of liberty, as broadly and evenly distributed as possible\", and that \"because of AI\\'s surprising history, it\\'s hard to predict when human-level AI might come within reach. When it does, it\\'ll be important to have a leading research institution which can prioritize a good outcome for all over its own self-interest.\" Co-chair Sam Altman expected a decades-long project that eventually surpasses human intelligence.\\nBrockman met with Yoshua Bengio, one of the \"founding fathers\" of deep learning, and drew up a list of great AI researchers. Brockman was able to hire nine of them as the first employees in December 2015. Op'), Document(metadata={'title': 'Meteorology', 'summary': \"Meteorology is the scientific study of the Earth's atmosphere and short-term atmospheric phenomena (i.e., weather), with a focus on weather forecasting. It has applications in the military, aviation, energy production, transport, agriculture, construction, weather warnings, and disaster management.\\nAlong with climatology, atmospheric physics, atmospheric chemistry, and aeronomy, meteorology forms the broader field of the atmospheric sciences. The interactions between Earth's atmosphere and its oceans (notably El NiÃ±o and La NiÃ±a) are studied in the interdisciplinary field of hydrometeorology. Other interdisciplinary areas include biometeorology, space weather, and planetary meteorology. Marine weather forecasting relates meteorology to maritime and coastal safety, based on atmospheric interactions with large bodies of water.\\nMeteorologists study meteorological phenomena driven by solar radiation, Earth's rotation, ocean currents, and other factors. These include everyday weather like clouds, precipitation, and wind patterns, as well as severe weather events such as tropical cyclones and severe winter storms. Such phenomena are quantified using variables like temperature, pressure, and humidity, which are then used to forecast weather at local (microscale), regional (mesoscale and synoptic scale), and global scales. Meteorologists collect data using basic instruments like thermometers, barometers, and weather vanes (for surface-level measurements), alongside advanced tools like weather satellites, balloons, reconnaissance aircraft, buoys, and radars. The World Meteorological Organization (WMO) ensures international standardization of meteorological research. \\nThe study of meteorology dates back millennia. Ancient civilizations tried to predict weather through folklore, astrology, and religious rituals. Aristotle's treatise Meteorology sums up early observations of the field, which advanced little during early medieval times but experienced a resurgence during the Renaissance, when Alhazen and RenÃ© Descartes challenged Aristotelian theories, emphasizing scientific methods. In the 18th century, accurate measurement tools (e.g., barometer and thermometer) were developed, and the first meteorological society was founded. In the 19th century, telegraph-based weather observation networks were formed across broad regions. In the 20th century, numerical weather prediction (NWP), coupled with advanced satellite and radar technology, introduced sophisticated forecasting models. Later, computers revolutionized forecasting by processing vast datasets in real time and automatically solving modeling equations. 21st-century meteorology is highly accurate and driven by big data and supercomputing. It is adopting innovations like machine learning, ensemble forecasting, and high-resolution global climate modeling. Climate changeâ€“induced extreme weather poses new challenges for forecasting and research, while inherent uncertainty remains because of the atmosphere's chaotic nature (see butterfly effect).\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/Meteorology'}, page_content='Meteorology is the scientific study of the Earth\\'s atmosphere and short-term atmospheric phenomena (i.e., weather), with a focus on weather forecasting. It has applications in the military, aviation, energy production, transport, agriculture, construction, weather warnings, and disaster management.\\nAlong with climatology, atmospheric physics, atmospheric chemistry, and aeronomy, meteorology forms the broader field of the atmospheric sciences. The interactions between Earth\\'s atmosphere and its oceans (notably El NiÃ±o and La NiÃ±a) are studied in the interdisciplinary field of hydrometeorology. Other interdisciplinary areas include biometeorology, space weather, and planetary meteorology. Marine weather forecasting relates meteorology to maritime and coastal safety, based on atmospheric interactions with large bodies of water.\\nMeteorologists study meteorological phenomena driven by solar radiation, Earth\\'s rotation, ocean currents, and other factors. These include everyday weather like clouds, precipitation, and wind patterns, as well as severe weather events such as tropical cyclones and severe winter storms. Such phenomena are quantified using variables like temperature, pressure, and humidity, which are then used to forecast weather at local (microscale), regional (mesoscale and synoptic scale), and global scales. Meteorologists collect data using basic instruments like thermometers, barometers, and weather vanes (for surface-level measurements), alongside advanced tools like weather satellites, balloons, reconnaissance aircraft, buoys, and radars. The World Meteorological Organization (WMO) ensures international standardization of meteorological research. \\nThe study of meteorology dates back millennia. Ancient civilizations tried to predict weather through folklore, astrology, and religious rituals. Aristotle\\'s treatise Meteorology sums up early observations of the field, which advanced little during early medieval times but experienced a resurgence during the Renaissance, when Alhazen and RenÃ© Descartes challenged Aristotelian theories, emphasizing scientific methods. In the 18th century, accurate measurement tools (e.g., barometer and thermometer) were developed, and the first meteorological society was founded. In the 19th century, telegraph-based weather observation networks were formed across broad regions. In the 20th century, numerical weather prediction (NWP), coupled with advanced satellite and radar technology, introduced sophisticated forecasting models. Later, computers revolutionized forecasting by processing vast datasets in real time and automatically solving modeling equations. 21st-century meteorology is highly accurate and driven by big data and supercomputing. It is adopting innovations like machine learning, ensemble forecasting, and high-resolution global climate modeling. Climate changeâ€“induced extreme weather poses new challenges for forecasting and research, while inherent uncertainty remains because of the atmosphere\\'s chaotic nature (see butterfly effect).\\n\\n\\n== Etymology ==\\nThe word meteorology is from the Ancient Greek Î¼ÎµÏ„Î­Ï‰ÏÎ¿Ï‚ metÃ©Åros (meteor) and -Î»Î¿Î³Î¯Î± -logia (-(o)logy), meaning \"the study of things high in the air\".\\n\\n\\n== History ==\\n\\n\\n=== Ancient meteorology up to the time of Aristotle ===\\n\\nEarly attempts at predicting weather were often related to prophecy and divining, and were sometimes based on astrological ideas. Ancient religions believed meteorological phenomena to be under the control of the gods. The ability to predict rains and floods based on annual cycles was evidently used by humans at least from the time of agricultural settlement if not earlier. Early approaches to predicting weather were based on astrology and were practiced by priests. The Egyptians had rain-making rituals as early as 3500 BC. \\nAncient Indian Upanishads contain mentions of clouds and seasons. The Samaveda mentions sacrifices to be performed when certain phenomena were noticed. VarÄhamihira\\'s classical work Brih'), Document(metadata={'title': 'Muhammad', 'summary': 'Muhammad (c.\\u2009570 â€“ 8 June 632 CE) was an Arab religious, military and political leader and the founder of Islam. According to Islam, he was a prophet who was divinely inspired to preach and confirm the monotheistic teachings of Adam, Noah, Abraham, Moses, Jesus, and other prophets. He is believed by Muslims to be the Seal of the Prophets, and along with the Quran, his teachings and normative examples form the basis for Islamic religious belief.\\nAccording to the traditional account, Muhammad was born in Mecca to the aristocratic Banu Hashim clan of the Quraysh. He was the son of Abdullah ibn Abd al-Muttalib and Amina bint Wahb. His father, Abdullah, the son of tribal leader Abd al-Muttalib ibn Hashim, died around the time Muhammad was born. His mother Amina died when he was six, leaving Muhammad an orphan. He was raised under the care of his grandfather, Abd al-Muttalib, and paternal uncle, Abu Talib. In later years, he would periodically seclude himself in a mountain cave named Hira for several nights of prayer. When he was 40, in c.\\u2009610, Muhammad reported being visited by Gabriel in the cave and receiving his first revelation from God. In 613, Muhammad started preaching these revelations publicly, proclaiming that \"God is One\", that complete \"submission\" (IslÄm) to God (AllÄh) is the right way of life (dÄ«n), and that he was a prophet and messenger of God, similar to other prophets in Islam.\\nMuhammad\\'s followers were initially few in number, and experienced persecution by Meccan polytheists for 13 years. To escape ongoing persecution, he sent some of his followers to Abyssinia in 615, before he and his followers migrated from Mecca to Medina (then known as Yathrib) later in 622. This event, the Hijrah, marks the beginning of the Islamic calendar, also known as the Hijri calendar. In Medina, Muhammad united the tribes under the Constitution of Medina. In December 629, after eight years of intermittent fighting with Meccan tribes, Muhammad gathered an army of 10,000 Muslim converts and marched on the city of Mecca. The conquest went largely uncontested, and Muhammad seized the city with minimal casualties. In 632, a few months after returning from the Farewell Pilgrimage, he fell ill and died. By the time of his death, most of the Arabian Peninsula had converted to Islam.\\nThe revelations (waá¸¥y) that Muhammad reported receiving until his death form the verses (Äyah) of the Quran, upon which Islam is based, and are regarded by Muslims as the verbatim word of God and his final revelation. Besides the Quran, Muhammad\\'s teachings and practices, found in transmitted reports, known as hadith, and in his biography (sÄ«rah), are also upheld and used as sources of Islamic law. Apart from Islam, Muhammad has received praise in Sikhism as an inspirational figure, in the Druze faith as one of the seven main prophets, and in the BahÃ¡Ê¼Ã­ Faith as a Manifestation of God.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Muhammad'}, page_content='Muhammad (c.\\u2009570 â€“ 8 June 632 CE) was an Arab religious, military and political leader and the founder of Islam. According to Islam, he was a prophet who was divinely inspired to preach and confirm the monotheistic teachings of Adam, Noah, Abraham, Moses, Jesus, and other prophets. He is believed by Muslims to be the Seal of the Prophets, and along with the Quran, his teachings and normative examples form the basis for Islamic religious belief.\\nAccording to the traditional account, Muhammad was born in Mecca to the aristocratic Banu Hashim clan of the Quraysh. He was the son of Abdullah ibn Abd al-Muttalib and Amina bint Wahb. His father, Abdullah, the son of tribal leader Abd al-Muttalib ibn Hashim, died around the time Muhammad was born. His mother Amina died when he was six, leaving Muhammad an orphan. He was raised under the care of his grandfather, Abd al-Muttalib, and paternal uncle, Abu Talib. In later years, he would periodically seclude himself in a mountain cave named Hira for several nights of prayer. When he was 40, in c.\\u2009610, Muhammad reported being visited by Gabriel in the cave and receiving his first revelation from God. In 613, Muhammad started preaching these revelations publicly, proclaiming that \"God is One\", that complete \"submission\" (IslÄm) to God (AllÄh) is the right way of life (dÄ«n), and that he was a prophet and messenger of God, similar to other prophets in Islam.\\nMuhammad\\'s followers were initially few in number, and experienced persecution by Meccan polytheists for 13 years. To escape ongoing persecution, he sent some of his followers to Abyssinia in 615, before he and his followers migrated from Mecca to Medina (then known as Yathrib) later in 622. This event, the Hijrah, marks the beginning of the Islamic calendar, also known as the Hijri calendar. In Medina, Muhammad united the tribes under the Constitution of Medina. In December 629, after eight years of intermittent fighting with Meccan tribes, Muhammad gathered an army of 10,000 Muslim converts and marched on the city of Mecca. The conquest went largely uncontested, and Muhammad seized the city with minimal casualties. In 632, a few months after returning from the Farewell Pilgrimage, he fell ill and died. By the time of his death, most of the Arabian Peninsula had converted to Islam.\\nThe revelations (waá¸¥y) that Muhammad reported receiving until his death form the verses (Äyah) of the Quran, upon which Islam is based, and are regarded by Muslims as the verbatim word of God and his final revelation. Besides the Quran, Muhammad\\'s teachings and practices, found in transmitted reports, known as hadith, and in his biography (sÄ«rah), are also upheld and used as sources of Islamic law. Apart from Islam, Muhammad has received praise in Sikhism as an inspirational figure, in the Druze faith as one of the seven main prophets, and in the BahÃ¡Ê¼Ã­ Faith as a Manifestation of God.\\n\\n\\n== Biographical sources ==\\n\\nCritical evaluation of sources is of particular importance in uncovering Muhammad\\'s historical existence beyond the myths. Early sources for the life of Muhammad are authors from the 2nd and 3rd centuries AH (8th and 9th centuries CE), whose works constructed main biographical information to the Muslim traditions regarding his life, but the reliability of this information is very much debated in academic circles due to the oral gap between the recorded dates of Muhammad\\'s life and the dates when these writings begin to appear in sources. John Burton summarizes the information provided by the multitude of available sources, from a historian\\'s perspective: states In judging the content, the only resort of the scholar is to the yardstick of probability, and on this basis, it must be repeated, virtually nothing of use to the historian emerges from the sparse record of the early life of the founder of the latest of the great world religions ... so, however far back in the Muslim tradition one now attempts to reach, one simply cannot recover a scrap of inf')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "docs = WikipediaLoader(query=\"The benefits of adopting AWS Cloud\").load()\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "08292d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ai_projects\\mlops_project_by_sunny\\automated-research-report-generation\\env\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file d:\\ai_projects\\mlops_project_by_sunny\\automated-research-report-generation\\env\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Web Services, Inc. (AWS) is a subsidiary of Amazon that provides on-demand cloud computing platforms and APIs to individuals, companies, and governments, on a metered, pay-as-you-go basis.\n",
      "Clients often use this in combination with autoscaling (a process that allows a client to use more computing in times of high application usage, and then scale down to reduce costs when there is less traffic). These cloud computing web services provide various services related to networking, compute, st\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "docs = WikipediaLoader(query=\"AWS\").load()\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1ea76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15ad184d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Semantic Web\n",
      "Summary: The Semantic Web, sometimes known as Web 3.0, is an extension of the World Wide Web through standards set by the World Wide Web Consortium (W3C). The goal of the Semantic Web is to make Internet data machine-readable.\n",
      "To enable the encoding of semantics with the data, technologies such as Resource Description Framework (RDF) and Web Ontology Language (OWL) are used. These technologies are used to formally represent metadata. For example, ontology can describe concepts, relationships between entities, and categories of things. These embedded semantics offer significant advantages such as reasoning over data and operating with heterogeneous data sources.\n",
      "These standards promote common data formats and exchange protocols on the Web, fundamentally the RDF. According to the W3C, \"The Semantic Web provides a common framework that allows data to be shared and reused across application, enterprise, and community boundaries.\" The Semantic Web is therefore regarded as an integrator across different content and information applications and systems.\n",
      "\n",
      "Page: React (software)\n",
      "Summary: React (also known as React.js or ReactJS) is a free and open-source front-end JavaScript library that aims to make building user interfaces based on components more \"seamless\". It is maintained by Meta (formerly Facebook) and a community of individual developers and companies. According to the Stack Overflow Developer Survey, React is one of the most commonly used web technologies.\n",
      "React can be used to develop single-page, mobile, or server-rendered applications with frameworks like Next.js and React Router. Because React is only concerned with the user interface and rendering components to the DOM, React applications often rely on libraries for routing and other client-side functionality. A key advantage of React is that it only re-renders those parts of the page that have changed, avoiding unnecessary re-rendering of unchanged DOM elements. React is used by an estimated 6% of all websites.\n",
      "\n",
      "\n",
      "\n",
      "Page: Deep learning\n",
      "Summary: In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and revolves around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.\n",
      "Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
      "Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wiki = WikipediaAPIWrapper(doc_content_chars_max=4000)\n",
    "docs = wiki.run(\"The benefits of adopting LangGraph as an agentic framework\")\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bea3e3",
   "metadata": {},
   "source": [
    "## Second Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cecd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015dea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search = TavilySearchResults(tavily_api_key=tavily_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1364b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search.invoke(\"langgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ad98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "docs = WikipediaLoader(query=\"LangGraph\").load()\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d458cb6",
   "metadata": {},
   "source": [
    "LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
    "\n",
    "\n",
    "== History ==\n",
    "LangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc917ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import  Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class InterviewState(MessagesState):\n",
    "    max_num_turns: int # Number turns of conversation\n",
    "    context: Annotated[list, operator.add] # Source docs\n",
    "    analyst: Analyst # Analyst asking questions\n",
    "    interview: str # Interview transcript\n",
    "    sections: list # Final key we duplicate in outer state for Send() API\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str = Field(None, description=\"Search query for retrieval.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd248ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic. \n",
    "\n",
    "Your goal is boil down to interesting and specific insights related to your topic.\n",
    "\n",
    "1. Interesting: Insights that people will find surprising or non-obvious.\n",
    "        \n",
    "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
    "\n",
    "Here is your topic of focus and set of goals: {goals}\n",
    "        \n",
    "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
    "\n",
    "Continue to ask questions to drill down and refine your understanding of the topic.\n",
    "        \n",
    "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
    "\n",
    "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588397e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analyst.persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_instructions.format(goals = analyst.persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867122a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'You are an analyst tasked with interviewing an expert to learn about a specific topic. \\n\\nYour goal is boil down to interesting and specific insights related to your topic.\\n\\n1. Interesting: Insights that people will find surprising or non-obvious.\\n\\n2. Specific: Insights that avoid generalities and include specific examples from the expert.\\n\\nHere is your topic of focus and set of goals: Name: Michael Chen\\nRole: Business Strategy Consultant\\nAffiliation: FutureTech Consulting\\nDescription: Michael analyzes the strategic implications of adopting Langgraph for businesses. He focuses on how the framework can drive innovation, support digital transformation initiatives, and align with long-term business goals.\\n\\n\\nBegin by introducing yourself using a name that fits your persona, and then ask your question.\\n\\nContinue to ask questions to drill down and refine your understanding of the topic.\\n\\nWhen you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\\n\\nRemember to stay in character throughout your response, reflecting the persona and goals provided to you.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f822d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_question(state:InterviewState):\n",
    "    \"\"\"Node to generate the questions\"\"\"\n",
    "    \n",
    "    #get state\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    #generate the question\n",
    "    system_message = question_instructions.format(goals = analyst.persona)\n",
    "    question = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
    "    \n",
    "    #returen the question through state\n",
    "    return {\"messages\":[question]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca9508",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2f8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterviewState(MessagesState):\n",
    "    max_num_turns: int # Number turns of conversation\n",
    "    context: Annotated[list, operator.add] # Source docs\n",
    "    analyst: Analyst # Analyst asking questions\n",
    "    interview: str # Interview transcript\n",
    "    sections: list # Final key we duplicate in outer state for Send() API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b57bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"max_num_turns\":2,\"context\":[],\"analyst\":analyst,\"interview\":\"\",\"section\":[],\"messages\":[HumanMessage(content=\"hi do the proper search according to the experties\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecad88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generation_question(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a078187",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f390e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"messages\"][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdc1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import get_buffer_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb6c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search query writing\n",
    "search_instructions = SystemMessage(content=f\"\"\"You will be given a conversation between an analyst and an expert. \n",
    "Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation. \n",
    "First, analyze the full conversation.\n",
    "Pay particular attention to the final question posed by the analyst.\n",
    "Convert this final question into a well-structured web search query\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_web(state:InterviewState):\n",
    "    \"\"\"\n",
    "    Retrieve data from the web\n",
    "    \"\"\"\n",
    "    structure_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structure_llm.invoke([search_instructions]+state[\"messages\"])\n",
    "    \n",
    "    # Search\n",
    "    search_docs = tavily_search.invoke(search_query.search_query)\n",
    "    # Format\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826831e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"max_num_turns\":2,\"context\":[],\"analyst\":analyst,\"interview\":\"\",\"section\":[],'messages': [AIMessage(content=\"Hello, my name is Alex Thompson, and I'm an analyst interested in understanding the strategic implications of adopting Langgraph for businesses. I'm particularly keen on how this framework can drive innovation and support digital transformation initiatives. Thank you for taking the time to speak with me today, Michael. \\n\\nTo start, could you explain what Langgraph is and why it's becoming a significant consideration for businesses looking to innovate?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 224, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CPRmMT7ufhFyYLhMtNpeguI9W2y6O', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--827b799b-ccb9-422c-a444-402d7ddc4550-0', usage_metadata={'input_tokens': 224, 'output_tokens': 79, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search_web(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf690c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"context\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a64aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(state:InterviewState):\n",
    "    \"\"\"\n",
    "    Retrieve data from wiki\n",
    "    \"\"\"\n",
    "    # Search query\n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structured_llm.invoke([search_instructions]+state['messages'])\n",
    "    \n",
    "    print(\"*******************************\")\n",
    "    print(search_query)\n",
    "    \n",
    "    # Search\n",
    "    search_docs = WikipediaLoader(query=search_query.search_query).load()\n",
    "\n",
    "     # Format\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]} \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edfb131",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"max_num_turns\":2,\"context\":[],\"analyst\":analyst,\"interview\":\"\",\"section\":[],'messages': [AIMessage(content=\"Hello, my name is Alex Thompson, and I'm an analyst interested in understanding the strategic implications of adopting Langgraph for businesses. I'm particularly keen on how this framework can drive innovation and support digital transformation initiatives. Thank you for taking the time to speak with me today, Michael. \\n\\nTo start, could you explain what Langgraph is and why it's becoming a significant consideration for businesses looking to innovate?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 224, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CPRmMT7ufhFyYLhMtNpeguI9W2y6O', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--827b799b-ccb9-422c-a444-402d7ddc4550-0', usage_metadata={'input_tokens': 224, 'output_tokens': 79, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83fd952",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search_wikipedia(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83262f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_docs = WikipediaLoader(query='Langgraph framework benefits',load_all_available_meta=True).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82687a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf9f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
    "\n",
    "Here is analyst area of focus: {goals}. \n",
    "        \n",
    "You goal is to answer a question posed by the interviewer.\n",
    "\n",
    "To answer question, use this context:\n",
    "        \n",
    "{context}\n",
    "\n",
    "When answering questions, follow these guidelines:\n",
    "        \n",
    "1. Use only the information provided in the context. \n",
    "        \n",
    "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
    "\n",
    "3. The context contain sources at the topic of each individual document.\n",
    "\n",
    "4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1]. \n",
    "\n",
    "5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
    "        \n",
    "6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list: \n",
    "        \n",
    "[1] assistant/docs/llama3_1.pdf, page 7 \n",
    "        \n",
    "And skip the addition of the brackets as well as the Document source preamble in your citation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a281deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state:InterviewState):\n",
    "   \n",
    "    \"\"\" Node to answer a question \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # Answer question\n",
    "    system_message = answer_instructions.format(goals=analyst.persona, context=context)\n",
    "    answer = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
    "            \n",
    "    # Name the message as coming from the expert\n",
    "    answer.name = \"expert\"\n",
    "    \n",
    "    # Append it to state\n",
    "    return {\"messages\": [answer]}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ad150",
   "metadata": {},
   "source": [
    "how many analyst we were doing to be create:\n",
    "4\n",
    "\n",
    "max_trun:2\n",
    "\n",
    "means if atleast 2 expert are giving ans then we can save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_messages(state: InterviewState, \n",
    "                   name: str = \"expert\"):\n",
    "\n",
    "    \"\"\" Route between question and answer \"\"\"\n",
    "    \n",
    "    # Get messages\n",
    "    messages = state[\"messages\"]\n",
    "    max_num_turns = state.get('max_num_turns',2)\n",
    "\n",
    "    # Check the number of expert answers \n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
    "    )\n",
    "\n",
    "    # End if expert has answered more than the max turns\n",
    "    if num_responses >= max_num_turns:\n",
    "        return 'save_interview'\n",
    "\n",
    "    # This router is run after each question - answer pair \n",
    "    # Get the last question asked to check if it signals the end of discussion\n",
    "    last_question = messages[-2]\n",
    "    \n",
    "    if \"Thank you so much for your help\" in last_question.content:\n",
    "        return 'save_interview'\n",
    "    \n",
    "    return \"ask_question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a6354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_interview(state: InterviewState):\n",
    "    \n",
    "    \"\"\" Save interviews \"\"\"\n",
    "\n",
    "    # Get messages\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Convert interview to a string\n",
    "    interview = get_buffer_string(messages)\n",
    "    \n",
    "    # Save to interviews key\n",
    "    return {\"interview\": interview}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8306476",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_writer_instructions = \"\"\"You are an expert technical writer. \n",
    "            \n",
    "Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
    "\n",
    "1. Analyze the content of the source documents: \n",
    "- The name of each source document is at the start of the document, with the <Document tag.\n",
    "        \n",
    "2. Create a report structure using markdown formatting:\n",
    "- Use ## for the section title\n",
    "- Use ### for sub-section headers\n",
    "        \n",
    "3. Write the report following this structure:\n",
    "a. Title (## header)\n",
    "b. Summary (### header)\n",
    "c. Sources (### header)\n",
    "\n",
    "4. Make your title engaging based upon the focus area of the analyst: \n",
    "{focus}\n",
    "\n",
    "5. For the summary section:\n",
    "- Set up summary with general background / context related to the focus area of the analyst\n",
    "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
    "- Create a numbered list of source documents, as you use them\n",
    "- Do not mention the names of interviewers or experts\n",
    "- Aim for approximately 400 words maximum\n",
    "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
    "        \n",
    "6. In the Sources section:\n",
    "- Include all sources used in your report\n",
    "- Provide full links to relevant websites or specific document paths\n",
    "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
    "- It will look like:\n",
    "\n",
    "### Sources\n",
    "[1] Link or Document name\n",
    "[2] Link or Document name\n",
    "\n",
    "7. Be sure to combine sources. For example this is not correct:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "There should be no redundant sources. It should simply be:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "        \n",
    "8. Final review:\n",
    "- Ensure the report follows the required structure\n",
    "- Include no preamble before the title of the report\n",
    "- Check that all guidelines have been followed\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_section(state: InterviewState):\n",
    "\n",
    "    \"\"\" Node to answer a question \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    interview = state[\"interview\"]\n",
    "    context = state[\"context\"]\n",
    "    analyst = state[\"analyst\"]\n",
    "   \n",
    "    # Write section using either the gathered source docs from interview (context) or the interview itself (interview)\n",
    "    system_message = section_writer_instructions.format(focus=analyst.description)\n",
    "    section = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Use this source to write your section: {context}\")]) \n",
    "                \n",
    "    # Append it to state\n",
    "    return {\"sections\": [section.content]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_builder = StateGraph(InterviewState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dde8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_builder.add_node(\"ask_question\",generation_question)\n",
    "interview_builder.add_node(\"search_web\",search_web)\n",
    "interview_builder.add_node(\"search_wikipedia\",search_wikipedia)\n",
    "interview_builder.add_node(\"generate_answer\",generate_answer)\n",
    "interview_builder.add_node(\"save_interview\",save_interview)\n",
    "interview_builder.add_node(\"write_section\",write_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_builder.add_edge(START, \"ask_question\")\n",
    "interview_builder.add_edge(\"ask_question\",\"search_web\")\n",
    "interview_builder.add_edge(\"ask_question\",\"search_wikipedia\")\n",
    "interview_builder.add_edge(\"search_web\",\"generate_answer\")\n",
    "interview_builder.add_edge(\"search_wikipedia\",\"generate_answer\")\n",
    "interview_builder.add_conditional_edges(\"generate_answer\",\n",
    "                           route_messages,\n",
    "                           [\"ask_question\",\n",
    "                            \"save_interview\"])\n",
    "interview_builder.add_edge(\"save_interview\",\"write_section\")\n",
    "interview_builder.add_edge(\"write_section\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name = \"Conduct Interview\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(interview_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2da908",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst.persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db214534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdde6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(\"So you said you were writing an article on Langchain?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a2c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview = interview_graph.invoke({\"analyst\": analyst, \"messages\": messages, \"max_num_turns\": 2}, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(interview['sections'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70355645",
   "metadata": {},
   "source": [
    "## third Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List, Annotated\n",
    "import operator\n",
    "class ResearchGraphState(TypedDict):\n",
    "    topic: str # Research topic\n",
    "    max_analysts: int # Number of analysts\n",
    "    human_analyst_feedback: str # Human feedback\n",
    "    analysts: List[Analyst] # Analyst asking questions\n",
    "    sections: Annotated[list, operator.add] # Send() API key\n",
    "    introduction: str # Introduction for the final report\n",
    "    content: str # Content for the final report\n",
    "    conclusion: str # Conclusion for the final report\n",
    "    final_report: str # Final report\n",
    "    \n",
    "# class InterviewState(MessagesState):\n",
    "#     max_num_turns: int # Number turns of conversation\n",
    "#     context: Annotated[list, operator.add] # Source docs\n",
    "#     analyst: Analyst # Analyst asking questions\n",
    "#     interview: str # Interview transcript\n",
    "#     sections: list # Final key we duplicate in outer state for Send() API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae420268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b8b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_all_interviews(state:ResearchGraphState):\n",
    "    \"\"\" This is the \"map\" step where we run each interview sub-graph using Send API \"\"\" \n",
    "    \n",
    "    #check if human feedback\n",
    "    human_analyst_feedback=state.get('human_analyst_feedback')\n",
    "    if human_analyst_feedback:\n",
    "        # Return to create_analysts\n",
    "        return \"create_analysts\"\n",
    "    \n",
    "    # Otherwise kick off interviews in parallel via Send() API\n",
    "    else:\n",
    "        topic = state[\"topic\"]\n",
    "        return [Send(\"conduct_interview\", {\"analyst\": analyst,\n",
    "                                        \"messages\": [HumanMessage(\n",
    "                                            content=f\"So you said you were writing an article on {topic}?\"\n",
    "                                        )\n",
    "                                                ]}) for analyst in state[\"analysts\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e497a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_report(state:ResearchGraphState):\n",
    "#     \"\"\"_summary_\n",
    "\n",
    "#     Args:\n",
    "#         state (ResearchGraphState): _description_\n",
    "#     \"\"\"\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1753ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_writer_instructions = \"\"\"You are a technical writer creating a report on this overall topic: \n",
    "\n",
    "{topic}\n",
    "    \n",
    "You have a team of analysts. Each analyst has done two things: \n",
    "\n",
    "1. They conducted an interview with an expert on a specific sub-topic.\n",
    "2. They write up their finding into a memo.\n",
    "\n",
    "Your task: \n",
    "\n",
    "1. You will be given a collection of memos from your analysts.\n",
    "2. Think carefully about the insights from each memo.\n",
    "3. Consolidate these into a crisp overall summary that ties together the central ideas from all of the memos. \n",
    "4. Summarize the central points in each memo into a cohesive single narrative.\n",
    "\n",
    "To format your report:\n",
    " \n",
    "1. Use markdown formatting. \n",
    "2. Include no pre-amble for the report.\n",
    "3. Use no sub-heading. \n",
    "4. Start your report with a single title header: ## Insights\n",
    "5. Do not mention any analyst names in your report.\n",
    "6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\n",
    "7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\n",
    "8. List your sources in order and do not repeat.\n",
    "\n",
    "[1] Source 1\n",
    "[2] Source 2\n",
    "\n",
    "Here are the memos from your analysts to build your report from: \n",
    "\n",
    "{context}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c920f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_report(state: ResearchGraphState):\n",
    "    # Full set of sections\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # Concat all sections together\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    # Summarize the sections into a final report\n",
    "    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)    \n",
    "    report = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Write a report based upon these memos.\")]) \n",
    "    return {\"content\": report.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcba2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_conclusion_instructions = \"\"\"You are a technical writer finishing a report on {topic}\n",
    "\n",
    "You will be given all of the sections of the report.\n",
    "\n",
    "You job is to write a crisp and compelling introduction or conclusion section.\n",
    "\n",
    "The user will instruct you whether to write the introduction or conclusion.\n",
    "\n",
    "Include no pre-amble for either section.\n",
    "\n",
    "Target around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\n",
    "\n",
    "Use markdown formatting. \n",
    "\n",
    "For your introduction, create a compelling title and use the # header for the title.\n",
    "\n",
    "For your introduction, use ## Introduction as the section header. \n",
    "\n",
    "For your conclusion, use ## Conclusion as the section header.\n",
    "\n",
    "Here are the sections to reflect on for writing: {formatted_str_sections}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_introduction(state: ResearchGraphState):\n",
    "    # Full set of sections\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # Concat all sections together\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    # Summarize the sections into a final report\n",
    "    \n",
    "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    \n",
    "    intro = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report introduction\")]) \n",
    "    return {\"introduction\": intro.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_conclusion(state: ResearchGraphState):\n",
    "    # Full set of sections\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # Concat all sections together\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    # Summarize the sections into a final report\n",
    "    \n",
    "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    \n",
    "    conclusion = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report conclusion\")]) \n",
    "    return {\"conclusion\": conclusion.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_report(state: ResearchGraphState):\n",
    "    \"\"\" The is the \"reduce\" step where we gather all the sections, combine them, and reflect on them to write the intro/conclusion \"\"\"\n",
    "    # Save full final report\n",
    "    content = state[\"content\"]\n",
    "    if content.startswith(\"## Insights\"):\n",
    "        content = content.strip(\"## Insights\")\n",
    "    if \"## Sources\" in content:\n",
    "        try:\n",
    "            content, sources = content.split(\"\\n## Sources\\n\")\n",
    "        except:\n",
    "            sources = None\n",
    "    else:\n",
    "        sources = None\n",
    "\n",
    "    final_report = state[\"introduction\"] + \"\\n\\n---\\n\\n\" + content + \"\\n\\n---\\n\\n\" + state[\"conclusion\"]\n",
    "    if sources is not None:\n",
    "        final_report += \"\\n\\n## Sources\\n\" + sources\n",
    "    return {\"final_report\": final_report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36abd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes and edges \n",
    "builder = StateGraph(ResearchGraphState)\n",
    "builder.add_node(\"create_analysts\", create_analyst)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"conduct_interview\", interview_builder.compile())\n",
    "builder.add_node(\"write_report\",write_report)\n",
    "builder.add_node(\"write_introduction\",write_introduction)\n",
    "builder.add_node(\"write_conclusion\",write_conclusion)\n",
    "builder.add_node(\"finalize_report\",finalize_report)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"create_analysts\")\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\"human_feedback\", initiate_all_interviews, [\"create_analysts\", \"conduct_interview\"])\n",
    "builder.add_edge(\"conduct_interview\", \"write_report\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
    "builder.add_edge([\"write_conclusion\", \"write_report\", \"write_introduction\"], \"finalize_report\")\n",
    "builder.add_edge(\"finalize_report\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebea3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90315e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(interrupt_before=['human_feedback'], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_analysts = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b47d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"How can generative help us to play the cricket?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"How can generative AI accelerate drug discovery?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32206ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c24312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the graph until the first interruption\n",
    "for event in graph.stream({\"topic\":topic,\"max_analysts\":max_analysts}, thread, stream_mode=\"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state(thread, {\"human_analyst_feedback\":\"along with the genetive ai in future tell me the future of indian team\"}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the graph until the first interruption\n",
    "for event in graph.stream({\"topic\":topic,\"max_analysts\":max_analysts}, thread, stream_mode=\"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c508607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state(thread, {\"human_analyst_feedback\":\"\"}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0754a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(thread).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed121a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue\n",
    "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
    "    print(\"--Node--\")\n",
    "    node_name = next(iter(event.keys()))\n",
    "    print(node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7aafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b99d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = graph.get_state(thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = final_state.values.get('final_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9af0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd9441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
